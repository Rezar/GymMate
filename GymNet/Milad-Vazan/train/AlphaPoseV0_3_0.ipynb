{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "AlphaPoseV0.3.0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sajJJG3krngt",
        "outputId": "764bc8cd-1d2a-489c-9649-abbe1ba7eb4d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQVH0gE47FE9",
        "outputId": "7e27d97a-0548-41e9-98f6-d64bddf917e7"
      },
      "source": [
        "!pip install -U torch==1.4 torchvision==0.5 -f https://download.pytorch.org/whl/cu101/torch_stable.html\n",
        "import os\n",
        "from os.path import exists, join, basename, splitext\n",
        "\n",
        "git_repo_url = 'https://github.com/MVIG-SJTU/AlphaPose.git'\n",
        "project_name = splitext(basename(git_repo_url))[0]\n",
        "if not exists(project_name):\n",
        "  # clone and install dependencies\n",
        "  !git clone -q {git_repo_url}\n",
        "  !pip install -q youtube-dl cython gdown\n",
        "  !pip install -q -U PyYAML\n",
        "  !apt-get install -y -q libyaml-dev\n",
        "  !cd {project_name} && git checkout 7be9809 && python setup.py build develop --user\n",
        "  \n",
        "import sys\n",
        "sys.path.append(project_name)\n",
        "import time\n",
        "import matplotlib\n",
        "import matplotlib.pylab as plt\n",
        "plt.rcParams[\"axes.grid\"] = False\n",
        "\n",
        "from IPython.display import YouTubeVideo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/cu101/torch_stable.html\n",
            "Collecting torch==1.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/3b/fa92ece1e58a6a48ec598bab327f39d69808133e5b2fb33002ca754e381e/torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4MB 21kB/s \n",
            "\u001b[?25hCollecting torchvision==0.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/32/cb0e4c43cd717da50258887b088471568990b5a749784c465a8a1962e021/torchvision-0.5.0-cp37-cp37m-manylinux1_x86_64.whl (4.0MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0MB 37.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5) (7.1.2)\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "  Found existing installation: torchvision 0.9.1+cu101\n",
            "    Uninstalling torchvision-0.9.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.1+cu101\n",
            "Successfully installed torch-1.4.0 torchvision-0.5.0\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 8.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 645kB 7.3MB/s \n",
            "\u001b[?25hReading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "Suggested packages:\n",
            "  libyaml-doc\n",
            "The following NEW packages will be installed:\n",
            "  libyaml-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 30 not upgraded.\n",
            "Need to get 55.7 kB of archives.\n",
            "After this operation, 246 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libyaml-dev amd64 0.1.7-2ubuntu3 [55.7 kB]\n",
            "Fetched 55.7 kB in 1s (93.9 kB/s)\n",
            "Selecting previously unselected package libyaml-dev:amd64.\n",
            "(Reading database ... 160980 files and directories currently installed.)\n",
            "Preparing to unpack .../libyaml-dev_0.1.7-2ubuntu3_amd64.deb ...\n",
            "Unpacking libyaml-dev:amd64 (0.1.7-2ubuntu3) ...\n",
            "Setting up libyaml-dev:amd64 (0.1.7-2ubuntu3) ...\n",
            "Note: checking out '7be9809'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at 7be9809 update setup.py\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "creating build/lib.linux-x86_64-3.7/alphapose\n",
            "copying alphapose/opt.py -> build/lib.linux-x86_64-3.7/alphapose\n",
            "copying alphapose/version.py -> build/lib.linux-x86_64-3.7/alphapose\n",
            "copying alphapose/__init__.py -> build/lib.linux-x86_64-3.7/alphapose\n",
            "creating build/lib.linux-x86_64-3.7/alphapose/models\n",
            "copying alphapose/models/fastpose_duc_dense.py -> build/lib.linux-x86_64-3.7/alphapose/models\n",
            "copying alphapose/models/fastpose.py -> build/lib.linux-x86_64-3.7/alphapose/models\n",
            "copying alphapose/models/__init__.py -> build/lib.linux-x86_64-3.7/alphapose/models\n",
            "copying alphapose/models/builder.py -> build/lib.linux-x86_64-3.7/alphapose/models\n",
            "copying alphapose/models/hrnet.py -> build/lib.linux-x86_64-3.7/alphapose/models\n",
            "copying alphapose/models/simplepose.py -> build/lib.linux-x86_64-3.7/alphapose/models\n",
            "copying alphapose/models/fastpose_duc.py -> build/lib.linux-x86_64-3.7/alphapose/models\n",
            "creating build/lib.linux-x86_64-3.7/alphapose/datasets\n",
            "copying alphapose/datasets/custom.py -> build/lib.linux-x86_64-3.7/alphapose/datasets\n",
            "copying alphapose/datasets/concat_dataset.py -> build/lib.linux-x86_64-3.7/alphapose/datasets\n",
            "copying alphapose/datasets/mpii.py -> build/lib.linux-x86_64-3.7/alphapose/datasets\n",
            "copying alphapose/datasets/mscoco.py -> build/lib.linux-x86_64-3.7/alphapose/datasets\n",
            "copying alphapose/datasets/__init__.py -> build/lib.linux-x86_64-3.7/alphapose/datasets\n",
            "copying alphapose/datasets/coco_det.py -> build/lib.linux-x86_64-3.7/alphapose/datasets\n",
            "creating build/lib.linux-x86_64-3.7/alphapose/utils\n",
            "copying alphapose/utils/registry.py -> build/lib.linux-x86_64-3.7/alphapose/utils\n",
            "copying alphapose/utils/vis.py -> build/lib.linux-x86_64-3.7/alphapose/utils\n",
            "copying alphapose/utils/detector.py -> build/lib.linux-x86_64-3.7/alphapose/utils\n",
            "copying alphapose/utils/webcam_detector.py -> build/lib.linux-x86_64-3.7/alphapose/utils\n",
            "copying alphapose/utils/pPose_nms.py -> build/lib.linux-x86_64-3.7/alphapose/utils\n",
            "copying alphapose/utils/config.py -> build/lib.linux-x86_64-3.7/alphapose/utils\n",
            "copying alphapose/utils/env.py -> build/lib.linux-x86_64-3.7/alphapose/utils\n",
            "copying alphapose/utils/transforms.py -> build/lib.linux-x86_64-3.7/alphapose/utils\n",
            "copying alphapose/utils/bbox.py -> build/lib.linux-x86_64-3.7/alphapose/utils\n",
            "copying alphapose/utils/writer.py -> build/lib.linux-x86_64-3.7/alphapose/utils\n",
            "copying alphapose/utils/__init__.py -> build/lib.linux-x86_64-3.7/alphapose/utils\n",
            "copying alphapose/utils/metrics.py -> build/lib.linux-x86_64-3.7/alphapose/utils\n",
            "copying alphapose/utils/logger.py -> build/lib.linux-x86_64-3.7/alphapose/utils\n",
            "creating build/lib.linux-x86_64-3.7/alphapose/utils/presets\n",
            "copying alphapose/utils/presets/simple_transform.py -> build/lib.linux-x86_64-3.7/alphapose/utils/presets\n",
            "copying alphapose/utils/presets/__init__.py -> build/lib.linux-x86_64-3.7/alphapose/utils/presets\n",
            "creating build/lib.linux-x86_64-3.7/alphapose/utils/roi_align\n",
            "copying alphapose/utils/roi_align/roi_align.py -> build/lib.linux-x86_64-3.7/alphapose/utils/roi_align\n",
            "copying alphapose/utils/roi_align/__init__.py -> build/lib.linux-x86_64-3.7/alphapose/utils/roi_align\n",
            "running build_ext\n",
            "building 'detector.nms.soft_nms_cpu' extension\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "creating build/temp.linux-x86_64-3.7/detector\n",
            "creating build/temp.linux-x86_64-3.7/detector/nms\n",
            "creating build/temp.linux-x86_64-3.7/detector/nms/src\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I/usr/include/python3.7m -c detector/nms/src/soft_nms_cpu.cpp -o build/temp.linux-x86_64-3.7/detector/nms/src/soft_nms_cpu.o -Wno-unused-function -Wno-write-strings -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=soft_nms_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1822:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kdetector/nms/src/soft_nms_cpu.cpp:638\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "creating build/lib.linux-x86_64-3.7/detector\n",
            "creating build/lib.linux-x86_64-3.7/detector/nms\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/detector/nms/src/soft_nms_cpu.o -o build/lib.linux-x86_64-3.7/detector/nms/soft_nms_cpu.cpython-37m-x86_64-linux-gnu.so\n",
            "building 'detector.nms.nms_cpu' extension\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c detector/nms/src/nms_cpu.cpp -o build/temp.linux-x86_64-3.7/detector/nms/src/nms_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=nms_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "detector/nms/src/nms_cpu.cpp: In instantiation of ‘\u001b[01m\u001b[Kat::Tensor nms_cpu_kernel(const at::Tensor&, float) [with scalar_t = double]\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kdetector/nms/src/nms_cpu.cpp:63:3:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[Kdetector/nms/src/nms_cpu.cpp:26:47:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = unsigned char]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   auto suppressed = \u001b[01;35m\u001b[Ksuppressed_t.data<uint8_t>()\u001b[m\u001b[K;\n",
            "                     \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:11:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kdetector/nms/src/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kdetector/nms/src/nms_cpu.cpp:27:37:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   auto order = \u001b[01;35m\u001b[Korder_t.data<int64_t>()\u001b[m\u001b[K;\n",
            "                \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:11:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kdetector/nms/src/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kdetector/nms/src/nms_cpu.cpp:28:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   auto \u001b[01;35m\u001b[Kx1\u001b[m\u001b[K = x1_t.data<scalar_t>();\n",
            "        \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:11:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kdetector/nms/src/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kdetector/nms/src/nms_cpu.cpp:29:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   auto \u001b[01;35m\u001b[Ky1\u001b[m\u001b[K = y1_t.data<scalar_t>();\n",
            "        \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:11:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kdetector/nms/src/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kdetector/nms/src/nms_cpu.cpp:30:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   auto \u001b[01;35m\u001b[Kx2\u001b[m\u001b[K = x2_t.data<scalar_t>();\n",
            "        \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:11:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kdetector/nms/src/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kdetector/nms/src/nms_cpu.cpp:31:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   auto \u001b[01;35m\u001b[Ky2\u001b[m\u001b[K = y2_t.data<scalar_t>();\n",
            "        \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:11:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kdetector/nms/src/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kdetector/nms/src/nms_cpu.cpp:32:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   auto \u001b[01;35m\u001b[Kareas\u001b[m\u001b[K = areas_t.data<scalar_t>();\n",
            "        \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:11:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kdetector/nms/src/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "detector/nms/src/nms_cpu.cpp: In instantiation of ‘\u001b[01m\u001b[Kat::Tensor nms_cpu_kernel(const at::Tensor&, float) [with scalar_t = float]\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kdetector/nms/src/nms_cpu.cpp:63:3:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[Kdetector/nms/src/nms_cpu.cpp:26:47:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = unsigned char]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   auto suppressed = \u001b[01;35m\u001b[Ksuppressed_t.data<uint8_t>()\u001b[m\u001b[K;\n",
            "                     \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:11:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kdetector/nms/src/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kdetector/nms/src/nms_cpu.cpp:27:37:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   auto order = \u001b[01;35m\u001b[Korder_t.data<int64_t>()\u001b[m\u001b[K;\n",
            "                \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:11:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kdetector/nms/src/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kdetector/nms/src/nms_cpu.cpp:28:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   auto \u001b[01;35m\u001b[Kx1\u001b[m\u001b[K = x1_t.data<scalar_t>();\n",
            "        \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:11:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kdetector/nms/src/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kdetector/nms/src/nms_cpu.cpp:29:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   auto \u001b[01;35m\u001b[Ky1\u001b[m\u001b[K = y1_t.data<scalar_t>();\n",
            "        \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:11:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kdetector/nms/src/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kdetector/nms/src/nms_cpu.cpp:30:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   auto \u001b[01;35m\u001b[Kx2\u001b[m\u001b[K = x2_t.data<scalar_t>();\n",
            "        \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:11:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kdetector/nms/src/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kdetector/nms/src/nms_cpu.cpp:31:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   auto \u001b[01;35m\u001b[Ky2\u001b[m\u001b[K = y2_t.data<scalar_t>();\n",
            "        \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:11:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kdetector/nms/src/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kdetector/nms/src/nms_cpu.cpp:32:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   auto \u001b[01;35m\u001b[Kareas\u001b[m\u001b[K = areas_t.data<scalar_t>();\n",
            "        \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:11:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kdetector/nms/src/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/detector/nms/src/nms_cpu.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.7/detector/nms/nms_cpu.cpython-37m-x86_64-linux-gnu.so\n",
            "building 'detector.nms.nms_cuda' extension\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c detector/nms/src/nms_cuda.cpp -o build/temp.linux-x86_64-3.7/detector/nms/src/nms_cuda.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=nms_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kdetector/nms/src/nms_cuda.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kdetector/nms/src/nms_cuda.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor nms(const at::Tensor&, float)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kdetector/nms/src/nms_cuda.cpp:4:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            " #define CHECK_CUDA(x) \u001b[01;36m\u001b[KAT_CHECK\u001b[m\u001b[K(x.type().is_cuda(), #x, \" must be a CUDAtensor \")\n",
            "                       \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kdetector/nms/src/nms_cuda.cpp:9:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_CUDA\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KC\u001b[m\u001b[KHECK_CUDA(dets);\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kdetector/nms/src/nms_cuda.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kdetector/nms/src/nms_cuda.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kdetector/nms/src/nms_cuda.cpp:4:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            " #define CHECK_CUDA(x) \u001b[01;36m\u001b[KAT_CHECK\u001b[m\u001b[K(x.type().is_cuda(), #x, \" must be a CUDAtensor \")\n",
            "                       \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kdetector/nms/src/nms_cuda.cpp:9:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_CUDA\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KC\u001b[m\u001b[KHECK_CUDA(dets);\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kdetector/nms/src/nms_cuda.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c detector/nms/src/nms_kernel.cu -o build/temp.linux-x86_64-3.7/detector/nms/src/nms_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=nms_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "\u001b[01m\u001b[Kdetector/nms/src/nms_kernel.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor nms_cuda(at::Tensor, float)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kdetector/nms/src/nms_kernel.cu:81:50:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   scalar_t* boxes_dev = boxes_sorted.data<scalar_\u001b[01;35m\u001b[Kt\u001b[m\u001b[K>();\n",
            "                                                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kdetector/nms/src/nms_kernel.cu:109:46:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   int64_t* keep_out = keep.data<int64_t>();\n",
            "                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/detector/nms/src/nms_cuda.o build/temp.linux-x86_64-3.7/detector/nms/src/nms_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.7/detector/nms/nms_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "building 'alphapose.utils.roi_align.roi_align_cuda' extension\n",
            "creating build/temp.linux-x86_64-3.7/alphapose\n",
            "creating build/temp.linux-x86_64-3.7/alphapose/utils\n",
            "creating build/temp.linux-x86_64-3.7/alphapose/utils/roi_align\n",
            "creating build/temp.linux-x86_64-3.7/alphapose/utils/roi_align/src\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c alphapose/utils/roi_align/src/roi_align_cuda.cpp -o build/temp.linux-x86_64-3.7/alphapose/utils/roi_align/src/roi_align_cuda.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=roi_align_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint roi_align_forward_cuda(at::Tensor, at::Tensor, int, int, float, int, at::Tensor)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:20:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            " #define CHECK_CUDA(x) \u001b[01;36m\u001b[KAT_CHECK\u001b[m\u001b[K(x.type().is_cuda(), #x, \" must be a CUDAtensor \")\n",
            "                       \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:24:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_CUDA\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KCHECK_CUDA\u001b[m\u001b[K(x);       \\\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:31:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_INPUT\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KC\u001b[m\u001b[KHECK_INPUT(features);\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:20:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            " #define CHECK_CUDA(x) \u001b[01;36m\u001b[KAT_CHECK\u001b[m\u001b[K(x.type().is_cuda(), #x, \" must be a CUDAtensor \")\n",
            "                       \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:24:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_CUDA\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KCHECK_CUDA\u001b[m\u001b[K(x);       \\\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:31:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_INPUT\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KC\u001b[m\u001b[KHECK_INPUT(features);\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:22:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KAT_CHECK\u001b[m\u001b[K(x.is_contiguous(), #x, \" must be contiguous \")\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:25:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_CONTIGUOUS\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KCHECK_CONTIGUOUS\u001b[m\u001b[K(x)\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:31:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_INPUT\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KC\u001b[m\u001b[KHECK_INPUT(features);\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:22:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KAT_CHECK\u001b[m\u001b[K(x.is_contiguous(), #x, \" must be contiguous \")\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:25:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_CONTIGUOUS\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KCHECK_CONTIGUOUS\u001b[m\u001b[K(x)\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:31:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_INPUT\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KC\u001b[m\u001b[KHECK_INPUT(features);\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:20:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            " #define CHECK_CUDA(x) \u001b[01;36m\u001b[KAT_CHECK\u001b[m\u001b[K(x.type().is_cuda(), #x, \" must be a CUDAtensor \")\n",
            "                       \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:24:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_CUDA\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KCHECK_CUDA\u001b[m\u001b[K(x);       \\\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:32:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_INPUT\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KC\u001b[m\u001b[KHECK_INPUT(rois);\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:20:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            " #define CHECK_CUDA(x) \u001b[01;36m\u001b[KAT_CHECK\u001b[m\u001b[K(x.type().is_cuda(), #x, \" must be a CUDAtensor \")\n",
            "                       \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:24:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_CUDA\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KCHECK_CUDA\u001b[m\u001b[K(x);       \\\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:32:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_INPUT\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KC\u001b[m\u001b[KHECK_INPUT(rois);\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:22:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KAT_CHECK\u001b[m\u001b[K(x.is_contiguous(), #x, \" must be contiguous \")\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:25:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_CONTIGUOUS\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KCHECK_CONTIGUOUS\u001b[m\u001b[K(x)\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:32:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_INPUT\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KC\u001b[m\u001b[KHECK_INPUT(rois);\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:22:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KAT_CHECK\u001b[m\u001b[K(x.is_contiguous(), #x, \" must be contiguous \")\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:25:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_CONTIGUOUS\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KCHECK_CONTIGUOUS\u001b[m\u001b[K(x)\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:32:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_INPUT\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KC\u001b[m\u001b[KHECK_INPUT(rois);\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:20:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            " #define CHECK_CUDA(x) \u001b[01;36m\u001b[KAT_CHECK\u001b[m\u001b[K(x.type().is_cuda(), #x, \" must be a CUDAtensor \")\n",
            "                       \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:24:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_CUDA\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KCHECK_CUDA\u001b[m\u001b[K(x);       \\\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:33:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_INPUT\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KC\u001b[m\u001b[KHECK_INPUT(output);\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:20:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            " #define CHECK_CUDA(x) \u001b[01;36m\u001b[KAT_CHECK\u001b[m\u001b[K(x.type().is_cuda(), #x, \" must be a CUDAtensor \")\n",
            "                       \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:24:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_CUDA\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KCHECK_CUDA\u001b[m\u001b[K(x);       \\\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:33:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_INPUT\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KC\u001b[m\u001b[KHECK_INPUT(output);\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:22:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KAT_CHECK\u001b[m\u001b[K(x.is_contiguous(), #x, \" must be contiguous \")\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:25:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_CONTIGUOUS\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KCHECK_CONTIGUOUS\u001b[m\u001b[K(x)\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:33:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_INPUT\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KC\u001b[m\u001b[KHECK_INPUT(output);\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:22:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KAT_CHECK\u001b[m\u001b[K(x.is_contiguous(), #x, \" must be contiguous \")\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:25:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_CONTIGUOUS\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KCHECK_CONTIGUOUS\u001b[m\u001b[K(x)\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:33:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_INPUT\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KC\u001b[m\u001b[KHECK_INPUT(output);\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint roi_align_backward_cuda(at::Tensor, at::Tensor, int, int, float, int, at::Tensor)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:20:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            " #define CHECK_CUDA(x) \u001b[01;36m\u001b[KAT_CHECK\u001b[m\u001b[K(x.type().is_cuda(), #x, \" must be a CUDAtensor \")\n",
            "                       \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:24:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_CUDA\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KCHECK_CUDA\u001b[m\u001b[K(x);       \\\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:59:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_INPUT\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KC\u001b[m\u001b[KHECK_INPUT(top_grad);\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:20:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            " #define CHECK_CUDA(x) \u001b[01;36m\u001b[KAT_CHECK\u001b[m\u001b[K(x.type().is_cuda(), #x, \" must be a CUDAtensor \")\n",
            "                       \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:24:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_CUDA\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KCHECK_CUDA\u001b[m\u001b[K(x);       \\\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:59:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_INPUT\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KC\u001b[m\u001b[KHECK_INPUT(top_grad);\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:22:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KAT_CHECK\u001b[m\u001b[K(x.is_contiguous(), #x, \" must be contiguous \")\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:25:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_CONTIGUOUS\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KCHECK_CONTIGUOUS\u001b[m\u001b[K(x)\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:59:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_INPUT\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KC\u001b[m\u001b[KHECK_INPUT(top_grad);\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:22:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KAT_CHECK\u001b[m\u001b[K(x.is_contiguous(), #x, \" must be contiguous \")\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:25:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_CONTIGUOUS\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KCHECK_CONTIGUOUS\u001b[m\u001b[K(x)\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:59:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_INPUT\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KC\u001b[m\u001b[KHECK_INPUT(top_grad);\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:20:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            " #define CHECK_CUDA(x) \u001b[01;36m\u001b[KAT_CHECK\u001b[m\u001b[K(x.type().is_cuda(), #x, \" must be a CUDAtensor \")\n",
            "                       \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:24:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_CUDA\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KCHECK_CUDA\u001b[m\u001b[K(x);       \\\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:60:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_INPUT\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KC\u001b[m\u001b[KHECK_INPUT(rois);\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:20:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            " #define CHECK_CUDA(x) \u001b[01;36m\u001b[KAT_CHECK\u001b[m\u001b[K(x.type().is_cuda(), #x, \" must be a CUDAtensor \")\n",
            "                       \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:24:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_CUDA\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KCHECK_CUDA\u001b[m\u001b[K(x);       \\\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:60:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_INPUT\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KC\u001b[m\u001b[KHECK_INPUT(rois);\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:22:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KAT_CHECK\u001b[m\u001b[K(x.is_contiguous(), #x, \" must be contiguous \")\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:25:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_CONTIGUOUS\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KCHECK_CONTIGUOUS\u001b[m\u001b[K(x)\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:60:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_INPUT\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KC\u001b[m\u001b[KHECK_INPUT(rois);\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:22:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KAT_CHECK\u001b[m\u001b[K(x.is_contiguous(), #x, \" must be contiguous \")\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:25:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_CONTIGUOUS\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KCHECK_CONTIGUOUS\u001b[m\u001b[K(x)\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:60:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_INPUT\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KC\u001b[m\u001b[KHECK_INPUT(rois);\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:20:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            " #define CHECK_CUDA(x) \u001b[01;36m\u001b[KAT_CHECK\u001b[m\u001b[K(x.type().is_cuda(), #x, \" must be a CUDAtensor \")\n",
            "                       \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:24:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_CUDA\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KCHECK_CUDA\u001b[m\u001b[K(x);       \\\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:61:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_INPUT\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KC\u001b[m\u001b[KHECK_INPUT(bottom_grad);\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:20:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            " #define CHECK_CUDA(x) \u001b[01;36m\u001b[KAT_CHECK\u001b[m\u001b[K(x.type().is_cuda(), #x, \" must be a CUDAtensor \")\n",
            "                       \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:24:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_CUDA\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KCHECK_CUDA\u001b[m\u001b[K(x);       \\\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:61:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_INPUT\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KC\u001b[m\u001b[KHECK_INPUT(bottom_grad);\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:22:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KAT_CHECK\u001b[m\u001b[K(x.is_contiguous(), #x, \" must be contiguous \")\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:25:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_CONTIGUOUS\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KCHECK_CONTIGUOUS\u001b[m\u001b[K(x)\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:61:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_INPUT\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KC\u001b[m\u001b[KHECK_INPUT(bottom_grad);\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:22:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KAT_CHECK\u001b[m\u001b[K(x.is_contiguous(), #x, \" must be contiguous \")\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:25:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_CONTIGUOUS\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KCHECK_CONTIGUOUS\u001b[m\u001b[K(x)\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:61:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_INPUT\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KC\u001b[m\u001b[KHECK_INPUT(bottom_grad);\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_cuda.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c alphapose/utils/roi_align/src/roi_align_kernel.cu -o build/temp.linux-x86_64-3.7/alphapose/utils/roi_align/src/roi_align_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=roi_align_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_kernel.cu:133:252:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_kernel.cu:133:305:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_kernel.cu:133:353:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_kernel.cu:133:728:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_kernel.cu:133:780:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_kernel.cu:133:827:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_kernel.cu:133:1208:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_kernel.cu:133:1264:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_kernel.cu:133:1315:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_kernel.cu:276:249:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_kernel.cu:276:302:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_kernel.cu:276:358:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_kernel.cu:276:372:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_kernel.cu:276:424:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_kernel.cu:276:479:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_kernel.cu:276:378:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_kernel.cu:276:434:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/utils/roi_align/src/roi_align_kernel.cu:276:493:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/alphapose/utils/roi_align/src/roi_align_cuda.o build/temp.linux-x86_64-3.7/alphapose/utils/roi_align/src/roi_align_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.7/alphapose/utils/roi_align/roi_align_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "building 'alphapose.models.layers.dcn.deform_conv_cuda' extension\n",
            "creating build/temp.linux-x86_64-3.7/alphapose/models\n",
            "creating build/temp.linux-x86_64-3.7/alphapose/models/layers\n",
            "creating build/temp.linux-x86_64-3.7/alphapose/models/layers/dcn\n",
            "creating build/temp.linux-x86_64-3.7/alphapose/models/layers/dcn/src\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c alphapose/models/layers/dcn/src/deform_conv_cuda.cpp -o build/temp.linux-x86_64-3.7/alphapose/models/layers/dcn/src/deform_conv_cuda.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=deform_conv_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid shape_check(at::Tensor, at::Tensor, at::Tensor*, at::Tensor, int, int, int, int, int, int, int, int, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:66:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(weight.ndimension() == 4,\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:66:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(weight.ndimension() == 4,\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:71:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(weight.is_contiguous(), \"weight tensor has to be contiguous\");\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:71:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(weight.is_contiguous(), \"weight tensor has to be contiguous\");\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:73:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(kW > 0 && kH > 0,\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:73:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(kW > 0 && kH > 0,\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:77:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK((weight.size(2) == kH && weight.size(3) == kW),\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:77:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK((weight.size(2) == kH && weight.size(3) == kW),\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:82:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(dW > 0 && dH > 0,\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:82:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(dW > 0 && dH > 0,\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:85:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:85:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:101:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(ndim == 3 || ndim == 4, \"3D or 4D input tensor expected but got: %s\",\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:101:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(ndim == 3 || ndim == 4, \"3D or 4D input tensor expected but got: %s\",\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:113:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(nInputPlane % deformable_group == 0,\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:113:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(nInputPlane % deformable_group == 0,\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:123:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(input.size(1) == nInputPlane,\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:123:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(input.size(1) == nInputPlane,\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:127:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK((inputHeight >= kH && inputWidth >= kW),\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:127:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK((inputHeight >= kH && inputWidth >= kW),\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:130:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK((offset.size(2) == outputHeight && offset.size(3) == outputWidth),\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:130:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK((offset.size(2) == outputHeight && offset.size(3) == outputWidth),\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:135:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK((offset.size(1) == deformable_group * 2 * kH * kW),\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:135:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK((offset.size(1) == deformable_group * 2 * kH * kW),\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:139:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(gradOutput->size(dimf) == nOutputPlane,\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:139:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(gradOutput->size(dimf) == nOutputPlane,\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:143:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK((gradOutput->size(dimh) == outputHeight &&\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:143:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK((gradOutput->size(dimh) == outputHeight &&\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint deform_conv_forward_cuda(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int, int, int, int, int, int, int, int, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:194:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK((offset.size(0) == batchSize), \"invalid batch size of offset\");\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:194:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK((offset.size(0) == batchSize), \"invalid batch size of offset\");\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint deform_conv_backward_input_cuda(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int, int, int, int, int, int, int, int, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:301:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK((offset.size(0) == batchSize), 3, \"invalid batch size of offset\");\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:301:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK((offset.size(0) == batchSize), 3, \"invalid batch size of offset\");\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint deform_conv_backward_parameters_cuda(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int, int, int, int, int, int, int, int, int, float, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:417:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK((offset.size(0) == batchSize), \"invalid batch size of offset\");\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:417:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK((offset.size(0) == batchSize), \"invalid batch size of offset\");\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid modulated_deform_conv_cuda_forward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int, int, int, int, int, int, int, int, int, bool)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:497:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(input.is_contiguous(), \"input tensor has to be contiguous\");\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:497:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(input.is_contiguous(), \"input tensor has to be contiguous\");\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:498:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(weight.is_contiguous(), \"weight tensor has to be contiguous\");\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:498:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(weight.is_contiguous(), \"weight tensor has to be contiguous\");\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid modulated_deform_conv_cuda_backward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int, int, int, int, int, int, int, int, int, bool)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:579:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(input.is_contiguous(), \"input tensor has to be contiguous\");\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:579:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(input.is_contiguous(), \"input tensor has to be contiguous\");\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:580:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(weight.is_contiguous(), \"weight tensor has to be contiguous\");\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:580:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(weight.is_contiguous(), \"weight tensor has to be contiguous\");\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c alphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu -o build/temp.linux-x86_64-3.7/alphapose/models/layers/dcn/src/deform_conv_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=deform_conv_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:258:247:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:258:310:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:258:361:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:258:842:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:258:904:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:258:954:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:258:1442:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:258:1508:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:258:1562:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:352:250:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:352:313:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:352:362:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:352:845:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:352:907:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:352:955:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:352:1445:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:352:1511:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:352:1563:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:450:250:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:450:305:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:450:368:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:450:425:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:450:980:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:450:1034:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:450:1096:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:450:1152:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:450:1714:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:450:1772:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:450:1838:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:450:1898:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:780:247:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:780:310:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:780:369:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:780:420:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:780:928:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:780:990:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:780:1048:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:780:1098:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:780:1613:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:780:1679:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:780:1741:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:780:1795:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:812:250:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:812:313:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:812:372:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:812:421:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:812:931:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:812:993:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:812:1051:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:812:1099:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:812:1616:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:812:1682:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:812:1744:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:812:1796:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:845:250:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:845:305:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:845:368:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:845:427:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:845:484:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:845:537:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:845:1133:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:845:1187:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:845:1249:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:845:1307:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:845:1363:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:845:1415:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:845:2018:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:845:2076:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:845:2142:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:845:2204:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:845:2264:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_conv_cuda_kernel.cu:845:2320:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "creating build/lib.linux-x86_64-3.7/alphapose/models/layers\n",
            "creating build/lib.linux-x86_64-3.7/alphapose/models/layers/dcn\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/alphapose/models/layers/dcn/src/deform_conv_cuda.o build/temp.linux-x86_64-3.7/alphapose/models/layers/dcn/src/deform_conv_cuda_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.7/alphapose/models/layers/dcn/deform_conv_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "building 'alphapose.models.layers.dcn.deform_pool_cuda' extension\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c alphapose/models/layers/dcn/src/deform_pool_cuda.cpp -o build/temp.linux-x86_64-3.7/alphapose/models/layers/dcn/src/deform_pool_cuda.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=deform_pool_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda.cpp:8\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid deform_psroi_pooling_cuda_forward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, float, int, int, int, int, int, float)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda.cpp:36:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(input.is_contiguous(), \"input tensor has to be contiguous\");\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda.cpp:8\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda.cpp:8\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda.cpp:36:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(input.is_contiguous(), \"input tensor has to be contiguous\");\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda.cpp:8\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda.cpp:8\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid deform_psroi_pooling_cuda_backward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, float, int, int, int, int, int, float)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda.cpp:62:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(out_grad.is_contiguous(), \"out_grad tensor has to be contiguous\");\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda.cpp:8\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda.cpp:8\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda.cpp:62:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(out_grad.is_contiguous(), \"out_grad tensor has to be contiguous\");\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda.cpp:8\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda.cpp:8\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda.cpp:63:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(input.is_contiguous(), \"input tensor has to be contiguous\");\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda.cpp:8\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda.cpp:8\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda.cpp:63:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(input.is_contiguous(), \"input tensor has to be contiguous\");\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda.cpp:8\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c alphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu -o build/temp.linux-x86_64-3.7/alphapose/models/layers/dcn/src/deform_pool_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=deform_pool_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:291:244:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:291:299:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:291:378:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:291:43:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:291:100:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:291:617:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:291:671:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:291:749:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:291:42:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:291:98:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:291:622:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:291:680:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:291:762:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:291:46:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:291:106:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:342:249:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:342:304:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:342:359:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:342:438:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:342:55:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:342:138:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:342:61:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:342:630:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:342:684:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:342:738:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:342:816:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:342:54:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:342:136:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:342:60:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:342:636:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:342:694:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:342:752:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:342:834:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:342:58:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:342:144:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kalphapose/models/layers/dcn/src/deform_pool_cuda_kernel.cu:342:64:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/alphapose/models/layers/dcn/src/deform_pool_cuda.o build/temp.linux-x86_64-3.7/alphapose/models/layers/dcn/src/deform_pool_cuda_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.7/alphapose/models/layers/dcn/deform_pool_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "running develop\n",
            "running egg_info\n",
            "creating alphapose.egg-info\n",
            "writing alphapose.egg-info/PKG-INFO\n",
            "writing dependency_links to alphapose.egg-info/dependency_links.txt\n",
            "writing requirements to alphapose.egg-info/requires.txt\n",
            "writing top-level names to alphapose.egg-info/top_level.txt\n",
            "writing manifest file 'alphapose.egg-info/SOURCES.txt'\n",
            "writing manifest file 'alphapose.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "copying build/lib.linux-x86_64-3.7/detector/nms/soft_nms_cpu.cpython-37m-x86_64-linux-gnu.so -> detector/nms\n",
            "copying build/lib.linux-x86_64-3.7/detector/nms/nms_cpu.cpython-37m-x86_64-linux-gnu.so -> detector/nms\n",
            "copying build/lib.linux-x86_64-3.7/detector/nms/nms_cuda.cpython-37m-x86_64-linux-gnu.so -> detector/nms\n",
            "copying build/lib.linux-x86_64-3.7/alphapose/utils/roi_align/roi_align_cuda.cpython-37m-x86_64-linux-gnu.so -> alphapose/utils/roi_align\n",
            "copying build/lib.linux-x86_64-3.7/alphapose/models/layers/dcn/deform_conv_cuda.cpython-37m-x86_64-linux-gnu.so -> alphapose/models/layers/dcn\n",
            "copying build/lib.linux-x86_64-3.7/alphapose/models/layers/dcn/deform_pool_cuda.cpython-37m-x86_64-linux-gnu.so -> alphapose/models/layers/dcn\n",
            "Creating /root/.local/lib/python3.7/site-packages/alphapose.egg-link (link to .)\n",
            "Adding alphapose 0.3.0+7be9809 to easy-install.pth file\n",
            "\n",
            "Installed /content/AlphaPose\n",
            "Processing dependencies for alphapose==0.3.0+7be9809\n",
            "Searching for munkres\n",
            "Reading https://pypi.tuna.tsinghua.edu.cn/simple/munkres/\n",
            "Downloading https://pypi.tuna.tsinghua.edu.cn/packages/90/ab/0301c945a704218bc9435f0e3c88884f6b19ef234d8899fb47ce1ccfd0c9/munkres-1.1.4-py2.py3-none-any.whl#sha256=6b01867d4a8480d865aea2326e4b8f7c46431e9e55b4a2e32d989307d7bced2a\n",
            "Best match: munkres 1.1.4\n",
            "Processing munkres-1.1.4-py2.py3-none-any.whl\n",
            "Installing munkres-1.1.4-py2.py3-none-any.whl to /root/.local/lib/python3.7/site-packages\n",
            "Adding munkres 1.1.4 to easy-install.pth file\n",
            "\n",
            "Installed /root/.local/lib/python3.7/site-packages/munkres-1.1.4-py3.7.egg\n",
            "Searching for tensorboardx\n",
            "Reading https://pypi.tuna.tsinghua.edu.cn/simple/tensorboardx/\n",
            "Downloading https://pypi.tuna.tsinghua.edu.cn/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl#sha256=236409a0144094b7ed1f7fc003d27c73a529b7fe326194a26b0f98d40c763779\n",
            "Best match: tensorboardX 2.2\n",
            "Processing tensorboardX-2.2-py2.py3-none-any.whl\n",
            "Installing tensorboardX-2.2-py2.py3-none-any.whl to /root/.local/lib/python3.7/site-packages\n",
            "Adding tensorboardX 2.2 to easy-install.pth file\n",
            "\n",
            "Installed /root/.local/lib/python3.7/site-packages/tensorboardX-2.2-py3.7.egg\n",
            "Searching for visdom\n",
            "Reading https://pypi.tuna.tsinghua.edu.cn/simple/visdom/\n",
            "Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c9/75/e078f5a2e1df7e0d3044749089fc2823e62d029cc027ed8ae5d71fafcbdc/visdom-0.1.8.9.tar.gz#sha256=c73ad23723c24a48156899f78dd76bd4538eba3edf9120b6c65a9528fa677126\n",
            "Best match: visdom 0.1.8.9\n",
            "Processing visdom-0.1.8.9.tar.gz\n",
            "Writing /tmp/easy_install-m4zuvjb5/visdom-0.1.8.9/setup.cfg\n",
            "Running visdom-0.1.8.9/setup.py -q bdist_egg --dist-dir /tmp/easy_install-m4zuvjb5/visdom-0.1.8.9/egg-dist-tmp-1ewkviaj\n",
            "warning: manifest_maker: MANIFEST.in, line 5: 'recursive-include' expects <dir> <pattern1> <pattern2> ...\n",
            "\n",
            "warning: no previously-included files matching '__pycache__' found under directory '*'\n",
            "warning: no previously-included files matching '*.py[co]' found under directory '*'\n",
            "creating /root/.local/lib/python3.7/site-packages/visdom-0.1.8.9-py3.7.egg\n",
            "Extracting visdom-0.1.8.9-py3.7.egg to /root/.local/lib/python3.7/site-packages\n",
            "Adding visdom 0.1.8.9 to easy-install.pth file\n",
            "Installing visdom script to /root/.local/bin\n",
            "\n",
            "Installed /root/.local/lib/python3.7/site-packages/visdom-0.1.8.9-py3.7.egg\n",
            "Searching for scipy==1.1.0\n",
            "Reading https://pypi.tuna.tsinghua.edu.cn/simple/scipy/\n",
            "Downloading https://pypi.tuna.tsinghua.edu.cn/packages/40/de/0c22c6754370ba6b1fa8e53bd6e514d4a41a181125d405a501c215cbdbd6/scipy-1.1.0-cp37-cp37m-manylinux1_x86_64.whl#sha256=8b984f0821577d889f3c7ca8445564175fb4ac7c7f9659b7c60bef95b2b70e76\n",
            "Best match: scipy 1.1.0\n",
            "Processing scipy-1.1.0-cp37-cp37m-manylinux1_x86_64.whl\n",
            "Installing scipy-1.1.0-cp37-cp37m-manylinux1_x86_64.whl to /root/.local/lib/python3.7/site-packages\n",
            "Adding scipy 1.1.0 to easy-install.pth file\n",
            "\n",
            "Installed /root/.local/lib/python3.7/site-packages/scipy-1.1.0-py3.7-linux-x86_64.egg\n",
            "Searching for terminaltables\n",
            "Reading https://pypi.tuna.tsinghua.edu.cn/simple/terminaltables/\n",
            "Downloading https://pypi.tuna.tsinghua.edu.cn/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz#sha256=f3eb0eb92e3833972ac36796293ca0906e998dc3be91fbe1f8615b331b853b81\n",
            "Best match: terminaltables 3.1.0\n",
            "Processing terminaltables-3.1.0.tar.gz\n",
            "Writing /tmp/easy_install-2jm51fj8/terminaltables-3.1.0/setup.cfg\n",
            "Running terminaltables-3.1.0/setup.py -q bdist_egg --dist-dir /tmp/easy_install-2jm51fj8/terminaltables-3.1.0/egg-dist-tmp-t8jvny2e\n",
            "Moving terminaltables-3.1.0-py3.7.egg to /root/.local/lib/python3.7/site-packages\n",
            "Adding terminaltables 3.1.0 to easy-install.pth file\n",
            "\n",
            "Installed /root/.local/lib/python3.7/site-packages/terminaltables-3.1.0-py3.7.egg\n",
            "Searching for websocket-client\n",
            "Reading https://pypi.tuna.tsinghua.edu.cn/simple/websocket-client/\n",
            "Downloading https://pypi.tuna.tsinghua.edu.cn/packages/08/33/80e0d4f60e84a1ddd9a03f340be1065a2a363c47ce65c4bd3bae65ce9631/websocket_client-0.58.0-py2.py3-none-any.whl#sha256=44b5df8f08c74c3d82d28100fdc81f4536809ce98a17f0757557813275fbb663\n",
            "Best match: websocket-client 0.58.0\n",
            "Processing websocket_client-0.58.0-py2.py3-none-any.whl\n",
            "Installing websocket_client-0.58.0-py2.py3-none-any.whl to /root/.local/lib/python3.7/site-packages\n",
            "Adding websocket-client 0.58.0 to easy-install.pth file\n",
            "Installing wsdump.py script to /root/.local/bin\n",
            "\n",
            "Installed /root/.local/lib/python3.7/site-packages/websocket_client-0.58.0-py3.7.egg\n",
            "Searching for torchfile\n",
            "Reading https://pypi.tuna.tsinghua.edu.cn/simple/torchfile/\n",
            "Downloading https://pypi.tuna.tsinghua.edu.cn/packages/91/af/5b305f86f2d218091af657ddb53f984ecbd9518ca9fe8ef4103a007252c9/torchfile-0.1.0.tar.gz#sha256=a53dfe134b737845a9f2cb24fe0585317874f965932cebdb0439d13c8da4136e\n",
            "Best match: torchfile 0.1.0\n",
            "Processing torchfile-0.1.0.tar.gz\n",
            "Writing /tmp/easy_install-q_ai30dc/torchfile-0.1.0/setup.cfg\n",
            "Running torchfile-0.1.0/setup.py -q bdist_egg --dist-dir /tmp/easy_install-q_ai30dc/torchfile-0.1.0/egg-dist-tmp-ixgzqvge\n",
            "/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:645: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
            "  % (opt, underscore_opt))\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "Moving torchfile-0.1.0-py3.7.egg to /root/.local/lib/python3.7/site-packages\n",
            "Adding torchfile 0.1.0 to easy-install.pth file\n",
            "\n",
            "Installed /root/.local/lib/python3.7/site-packages/torchfile-0.1.0-py3.7.egg\n",
            "Searching for jsonpatch\n",
            "Reading https://pypi.tuna.tsinghua.edu.cn/simple/jsonpatch/\n",
            "Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a3/55/f7c93bae36d869292aedfbcbae8b091386194874f16390d680136edd2b28/jsonpatch-1.32-py2.py3-none-any.whl#sha256=26ac385719ac9f54df8a2f0827bb8253aa3ea8ab7b3368457bcdb8c14595a397\n",
            "Best match: jsonpatch 1.32\n",
            "Processing jsonpatch-1.32-py2.py3-none-any.whl\n",
            "Installing jsonpatch-1.32-py2.py3-none-any.whl to /root/.local/lib/python3.7/site-packages\n",
            "Adding jsonpatch 1.32 to easy-install.pth file\n",
            "Installing jsondiff script to /root/.local/bin\n",
            "Installing jsonpatch script to /root/.local/bin\n",
            "\n",
            "Installed /root/.local/lib/python3.7/site-packages/jsonpatch-1.32-py3.7.egg\n",
            "Searching for jsonpointer>=1.9\n",
            "Reading https://pypi.tuna.tsinghua.edu.cn/simple/jsonpointer/\n",
            "Downloading https://pypi.tuna.tsinghua.edu.cn/packages/23/52/05f67532aa922e494c351344e0d9624a01f74f5dd8402fe0d1b563a6e6fc/jsonpointer-2.1-py2.py3-none-any.whl#sha256=150f80c5badd02c757da6644852f612f88e8b4bc2f9852dcbf557c8738919686\n",
            "Best match: jsonpointer 2.1\n",
            "Processing jsonpointer-2.1-py2.py3-none-any.whl\n",
            "Installing jsonpointer-2.1-py2.py3-none-any.whl to /root/.local/lib/python3.7/site-packages\n",
            "Adding jsonpointer 2.1 to easy-install.pth file\n",
            "Installing jsonpointer script to /root/.local/bin\n",
            "\n",
            "Installed /root/.local/lib/python3.7/site-packages/jsonpointer-2.1-py3.7.egg\n",
            "Searching for pycocotools==2.0.2\n",
            "Best match: pycocotools 2.0.2\n",
            "Adding pycocotools 2.0.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for torchvision==0.5.0\n",
            "Best match: torchvision 0.5.0\n",
            "Adding torchvision 0.5.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for torch==1.4.0\n",
            "Best match: torch 1.4.0\n",
            "Adding torch 1.4.0 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /root/.local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /root/.local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for PyYAML==5.4.1\n",
            "Best match: PyYAML 5.4.1\n",
            "Adding PyYAML 5.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for easydict==1.9\n",
            "Best match: easydict 1.9\n",
            "Adding easydict 1.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tqdm==4.41.1\n",
            "Best match: tqdm 4.41.1\n",
            "Adding tqdm 4.41.1 to easy-install.pth file\n",
            "Installing tqdm script to /root/.local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for matplotlib==3.2.2\n",
            "Best match: matplotlib 3.2.2\n",
            "Adding matplotlib 3.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for opencv-python==4.1.2.30\n",
            "Best match: opencv-python 4.1.2.30\n",
            "Adding opencv-python 4.1.2.30 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for six==1.15.0\n",
            "Best match: six 1.15.0\n",
            "Adding six 1.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Cython==0.29.22\n",
            "Best match: Cython 0.29.22\n",
            "Adding Cython 0.29.22 to easy-install.pth file\n",
            "Installing cygdb script to /root/.local/bin\n",
            "Installing cython script to /root/.local/bin\n",
            "Installing cythonize script to /root/.local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for setuptools==54.2.0\n",
            "Best match: setuptools 54.2.0\n",
            "Adding setuptools 54.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Pillow==7.1.2\n",
            "Best match: Pillow 7.1.2\n",
            "Adding Pillow 7.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for numpy==1.19.5\n",
            "Best match: numpy 1.19.5\n",
            "Adding numpy 1.19.5 to easy-install.pth file\n",
            "Installing f2py script to /root/.local/bin\n",
            "Installing f2py3 script to /root/.local/bin\n",
            "Installing f2py3.7 script to /root/.local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for protobuf==3.12.4\n",
            "Best match: protobuf 3.12.4\n",
            "Adding protobuf 3.12.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pyzmq==22.0.3\n",
            "Best match: pyzmq 22.0.3\n",
            "Adding pyzmq 22.0.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tornado==5.1.1\n",
            "Best match: tornado 5.1.1\n",
            "Adding tornado 5.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for requests==2.23.0\n",
            "Best match: requests 2.23.0\n",
            "Adding requests 2.23.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for python-dateutil==2.8.1\n",
            "Best match: python-dateutil 2.8.1\n",
            "Adding python-dateutil 2.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pyparsing==2.4.7\n",
            "Best match: pyparsing 2.4.7\n",
            "Adding pyparsing 2.4.7 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for kiwisolver==1.3.1\n",
            "Best match: kiwisolver 1.3.1\n",
            "Adding kiwisolver 1.3.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for cycler==0.10.0\n",
            "Best match: cycler 0.10.0\n",
            "Adding cycler 0.10.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for urllib3==1.24.3\n",
            "Best match: urllib3 1.24.3\n",
            "Adding urllib3 1.24.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for idna==2.10\n",
            "Best match: idna 2.10\n",
            "Adding idna 2.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for chardet==3.0.4\n",
            "Best match: chardet 3.0.4\n",
            "Adding chardet 3.0.4 to easy-install.pth file\n",
            "Installing chardetect script to /root/.local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for certifi==2020.12.5\n",
            "Best match: certifi 2020.12.5\n",
            "Adding certifi 2020.12.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Finished processing dependencies for alphapose==0.3.0+7be9809\n",
            "\n",
            "Install `cython_bbox`...\n",
            "Collecting git+https://github.com/yanfengliu/cython_bbox.git\n",
            "  Cloning https://github.com/yanfengliu/cython_bbox.git to /tmp/pip-req-build-9wcxn1ev\n",
            "  Running command git clone -q https://github.com/yanfengliu/cython_bbox.git /tmp/pip-req-build-9wcxn1ev\n",
            "Building wheels for collected packages: cython-bbox\n",
            "  Building wheel for cython-bbox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cython-bbox: filename=cython_bbox-0.1.3-cp37-cp37m-linux_x86_64.whl size=58987 sha256=dc5ee6a7ac8390d29b02732a7390397f257ec9dffa3c95587669df39792cfb5e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-sm0zyslv/wheels/cd/ad/0c/7c521537a87c222f66d52728bc3836ed989e4e0d221255b16d\n",
            "Successfully built cython-bbox\n",
            "Installing collected packages: cython-bbox\n",
            "Successfully installed cython-bbox-0.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibzztWRQF3-f"
      },
      "source": [
        "## Download pretrained models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbmT4eNY8ST6",
        "outputId": "7b04505e-98d9-4396-a2e3-a09bd859d677"
      },
      "source": [
        "yolo_pretrained_model_path = join(project_name, 'detector/yolo/data/yolov3-spp.weights')\n",
        "if not exists(yolo_pretrained_model_path):\n",
        "  # download the YOLO weights\n",
        "  !mkdir -p {project_name}/detector/yolo/data\n",
        "  !gdown -O {yolo_pretrained_model_path} https://drive.google.com/uc?id=1D47msNOOiJKvPOXlnpyzdKA3k6E97NTC\n",
        "\n",
        "#tracker_pretrained_model_path = join(project_name, 'detector/tracker/data/jde.1088x608.uncertainty.pt')\n",
        "#if not exists(tracker_pretrained_model_path):\n",
        "#  # tracker weights\n",
        "#  !mkdir -p {project_name}/detector/tracker/data\n",
        "#  !gdown -O {tracker_pretrained_model_path} https://drive.google.com/uc?id=1nlnuYfGNuHWZztQHXwVZSL_FvfE551pA\n",
        "\n",
        "# ResNet152 backbone 73.3 AP\n",
        "pretrained_model_path = join(project_name, 'pretrained_models/fast_421_res152_256x192.pth')\n",
        "pretrained_model_config_path = join(project_name, 'configs/coco/resnet/256x192_res152_lr1e-3_1x-duc.yaml')\n",
        "if not exists(pretrained_model_path):\n",
        "  # download the pretrained model\n",
        "  !gdown -O {pretrained_model_path} https://drive.google.com/uc?id=1kfyedqyn8exjbbNmYq8XGd2EooQjPtF9"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1D47msNOOiJKvPOXlnpyzdKA3k6E97NTC\n",
            "To: /content/AlphaPose/detector/yolo/data/yolov3-spp.weights\n",
            "252MB [00:01, 190MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1kfyedqyn8exjbbNmYq8XGd2EooQjPtF9\n",
            "To: /content/AlphaPose/pretrained_models/fast_421_res152_256x192.pth\n",
            "334MB [00:03, 89.2MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuYOch1THEV2"
      },
      "source": [
        "folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPnFN8J2H5c4"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "dataset = pd.read_csv('/content/drive/MyDrive/pm/5.csv')\n",
        "parent_dir= \"/content/drive/MyDrive/pm\"\n",
        "for index, row in dataset.iterrows():\n",
        "    path = os.path.join(parent_dir, row[\"add\"])\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bZZisEGqOlF",
        "outputId": "bff0a508-0167-4c70-8559-0adeccec3323"
      },
      "source": [
        "import os\n",
        "from csv import DictReader\n",
        "with open('/content/drive/MyDrive/pm/m2.csv', 'r') as read_obj:\n",
        "    csv_dict_reader = DictReader(read_obj)\n",
        "    for row in csv_dict_reader:\n",
        "      dirname = row[\"folder\"]\n",
        "      diradd = row[\"name\"]\n",
        "      print(\"Read video from: \",dirname)\n",
        "      !cd {project_name} && python3 scripts/demo_inference.py --sp --video \"{dirname}\" --outdir \"{diradd}\" --save_video --checkpoint ../{pretrained_model_path} --cfg ../{pretrained_model_config_path}\n",
        "      print(\"Results have been written to: \",diradd)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 289/289 [00:10<00:00, 26.74it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 164 images in the queue...\n",
            "===========================> Rendering remaining 139 images in the queue...\n",
            "===========================> Rendering remaining 114 images in the queue...\n",
            "===========================> Rendering remaining 90 images in the queue...\n",
            "===========================> Rendering remaining 22 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 338/338 [00:14<00:00, 23.76it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 186 images in the queue...\n",
            "===========================> Rendering remaining 162 images in the queue...\n",
            "===========================> Rendering remaining 137 images in the queue...\n",
            "===========================> Rendering remaining 113 images in the queue...\n",
            "===========================> Rendering remaining 87 images in the queue...\n",
            "===========================> Rendering remaining 15 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 377/377 [00:15<00:00, 23.91it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 202 images in the queue...\n",
            "===========================> Rendering remaining 177 images in the queue...\n",
            "===========================> Rendering remaining 152 images in the queue...\n",
            "===========================> Rendering remaining 127 images in the queue...\n",
            "===========================> Rendering remaining 105 images in the queue...\n",
            "===========================> Rendering remaining 69 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 324/324 [00:12<00:00, 26.25it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 196 images in the queue...\n",
            "===========================> Rendering remaining 174 images in the queue...\n",
            "===========================> Rendering remaining 151 images in the queue...\n",
            "===========================> Rendering remaining 128 images in the queue...\n",
            "===========================> Rendering remaining 105 images in the queue...\n",
            "===========================> Rendering remaining 78 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 261/261 [00:10<00:00, 25.83it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 145 images in the queue...\n",
            "===========================> Rendering remaining 121 images in the queue...\n",
            "===========================> Rendering remaining 97 images in the queue...\n",
            "===========================> Rendering remaining 44 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 324/324 [00:11<00:00, 27.63it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 198 images in the queue...\n",
            "===========================> Rendering remaining 174 images in the queue...\n",
            "===========================> Rendering remaining 151 images in the queue...\n",
            "===========================> Rendering remaining 127 images in the queue...\n",
            "===========================> Rendering remaining 103 images in the queue...\n",
            "===========================> Rendering remaining 65 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 285/285 [00:10<00:00, 28.24it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 163 images in the queue...\n",
            "===========================> Rendering remaining 138 images in the queue...\n",
            "===========================> Rendering remaining 113 images in the queue...\n",
            "===========================> Rendering remaining 88 images in the queue...\n",
            "===========================> Rendering remaining 17 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 414/414 [00:14<00:00, 28.84it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 167 images in the queue...\n",
            "===========================> Rendering remaining 142 images in the queue...\n",
            "===========================> Rendering remaining 120 images in the queue...\n",
            "===========================> Rendering remaining 100 images in the queue...\n",
            "===========================> Rendering remaining 60 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 309/309 [00:11<00:00, 26.99it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 163 images in the queue...\n",
            "===========================> Rendering remaining 137 images in the queue...\n",
            "===========================> Rendering remaining 111 images in the queue...\n",
            "===========================> Rendering remaining 84 images in the queue...\n",
            "===========================> Rendering remaining 3 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 328/328 [00:17<00:00, 18.56it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 159 images in the queue...\n",
            "===========================> Rendering remaining 136 images in the queue...\n",
            "===========================> Rendering remaining 114 images in the queue...\n",
            "===========================> Rendering remaining 90 images in the queue...\n",
            "===========================> Rendering remaining 25 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 529/529 [00:28<00:00, 18.44it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 254 images in the queue...\n",
            "===========================> Rendering remaining 229 images in the queue...\n",
            "===========================> Rendering remaining 204 images in the queue...\n",
            "===========================> Rendering remaining 179 images in the queue...\n",
            "===========================> Rendering remaining 154 images in the queue...\n",
            "===========================> Rendering remaining 129 images in the queue...\n",
            "===========================> Rendering remaining 105 images in the queue...\n",
            "===========================> Rendering remaining 69 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 263/263 [00:07<00:00, 33.52it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 164 images in the queue...\n",
            "===========================> Rendering remaining 141 images in the queue...\n",
            "===========================> Rendering remaining 116 images in the queue...\n",
            "===========================> Rendering remaining 94 images in the queue...\n",
            "===========================> Rendering remaining 37 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 304/304 [00:10<00:00, 28.82it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 159 images in the queue...\n",
            "===========================> Rendering remaining 133 images in the queue...\n",
            "===========================> Rendering remaining 110 images in the queue...\n",
            "===========================> Rendering remaining 89 images in the queue...\n",
            "===========================> Rendering remaining 22 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 286/286 [00:11<00:00, 25.91it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 162 images in the queue...\n",
            "===========================> Rendering remaining 137 images in the queue...\n",
            "===========================> Rendering remaining 111 images in the queue...\n",
            "===========================> Rendering remaining 86 images in the queue...\n",
            "===========================> Rendering remaining 8 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 308/308 [00:19<00:00, 15.85it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 216 images in the queue...\n",
            "===========================> Rendering remaining 201 images in the queue...\n",
            "===========================> Rendering remaining 186 images in the queue...\n",
            "===========================> Rendering remaining 171 images in the queue...\n",
            "===========================> Rendering remaining 156 images in the queue...\n",
            "===========================> Rendering remaining 142 images in the queue...\n",
            "===========================> Rendering remaining 127 images in the queue...\n",
            "===========================> Rendering remaining 112 images in the queue...\n",
            "===========================> Rendering remaining 97 images in the queue...\n",
            "===========================> Rendering remaining 71 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 514/514 [00:26<00:00, 19.26it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 252 images in the queue...\n",
            "===========================> Rendering remaining 226 images in the queue...\n",
            "===========================> Rendering remaining 200 images in the queue...\n",
            "===========================> Rendering remaining 175 images in the queue...\n",
            "===========================> Rendering remaining 149 images in the queue...\n",
            "===========================> Rendering remaining 125 images in the queue...\n",
            "===========================> Rendering remaining 99 images in the queue...\n",
            "===========================> Rendering remaining 52 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "  0% 0/376 [00:00<?, ?it/s]Try to use other video encoders...\n",
            "100% 376/376 [00:16<00:00, 22.85it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 196 images in the queue...\n",
            "===========================> Rendering remaining 170 images in the queue...\n",
            "===========================> Rendering remaining 145 images in the queue...\n",
            "===========================> Rendering remaining 120 images in the queue...\n",
            "===========================> Rendering remaining 94 images in the queue...\n",
            "===========================> Rendering remaining 32 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 300/300 [00:10<00:00, 29.53it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 187 images in the queue...\n",
            "===========================> Rendering remaining 161 images in the queue...\n",
            "===========================> Rendering remaining 136 images in the queue...\n",
            "===========================> Rendering remaining 110 images in the queue...\n",
            "===========================> Rendering remaining 84 images in the queue...\n",
            "===========================> Rendering remaining 2 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 272/272 [00:08<00:00, 32.07it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 164 images in the queue...\n",
            "===========================> Rendering remaining 139 images in the queue...\n",
            "===========================> Rendering remaining 114 images in the queue...\n",
            "===========================> Rendering remaining 89 images in the queue...\n",
            "===========================> Rendering remaining 20 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 455/455 [00:21<00:00, 21.24it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 225 images in the queue...\n",
            "===========================> Rendering remaining 198 images in the queue...\n",
            "===========================> Rendering remaining 172 images in the queue...\n",
            "===========================> Rendering remaining 147 images in the queue...\n",
            "===========================> Rendering remaining 121 images in the queue...\n",
            "===========================> Rendering remaining 95 images in the queue...\n",
            "===========================> Rendering remaining 34 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 240/240 [00:08<00:00, 27.76it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 139 images in the queue...\n",
            "===========================> Rendering remaining 114 images in the queue...\n",
            "===========================> Rendering remaining 89 images in the queue...\n",
            "===========================> Rendering remaining 16 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 441/441 [00:25<00:00, 17.41it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 204 images in the queue...\n",
            "===========================> Rendering remaining 177 images in the queue...\n",
            "===========================> Rendering remaining 152 images in the queue...\n",
            "===========================> Rendering remaining 128 images in the queue...\n",
            "===========================> Rendering remaining 104 images in the queue...\n",
            "===========================> Rendering remaining 64 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 294/294 [00:10<00:00, 27.43it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 178 images in the queue...\n",
            "===========================> Rendering remaining 155 images in the queue...\n",
            "===========================> Rendering remaining 131 images in the queue...\n",
            "===========================> Rendering remaining 108 images in the queue...\n",
            "===========================> Rendering remaining 85 images in the queue...\n",
            "===========================> Rendering remaining 4 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 379/379 [00:16<00:00, 22.68it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 203 images in the queue...\n",
            "===========================> Rendering remaining 178 images in the queue...\n",
            "===========================> Rendering remaining 157 images in the queue...\n",
            "===========================> Rendering remaining 133 images in the queue...\n",
            "===========================> Rendering remaining 108 images in the queue...\n",
            "===========================> Rendering remaining 78 images in the queue...\n",
            "===========================> Rendering remaining 1 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 391/391 [00:19<00:00, 20.31it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 255 images in the queue...\n",
            "===========================> Rendering remaining 236 images in the queue...\n",
            "===========================> Rendering remaining 218 images in the queue...\n",
            "===========================> Rendering remaining 200 images in the queue...\n",
            "===========================> Rendering remaining 183 images in the queue...\n",
            "===========================> Rendering remaining 166 images in the queue...\n",
            "===========================> Rendering remaining 148 images in the queue...\n",
            "===========================> Rendering remaining 130 images in the queue...\n",
            "===========================> Rendering remaining 114 images in the queue...\n",
            "===========================> Rendering remaining 98 images in the queue...\n",
            "===========================> Rendering remaining 65 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 387/387 [00:17<00:00, 22.35it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 206 images in the queue...\n",
            "===========================> Rendering remaining 180 images in the queue...\n",
            "===========================> Rendering remaining 155 images in the queue...\n",
            "===========================> Rendering remaining 129 images in the queue...\n",
            "===========================> Rendering remaining 104 images in the queue...\n",
            "===========================> Rendering remaining 63 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 376/376 [00:16<00:00, 22.74it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 186 images in the queue...\n",
            "===========================> Rendering remaining 165 images in the queue...\n",
            "===========================> Rendering remaining 139 images in the queue...\n",
            "===========================> Rendering remaining 115 images in the queue...\n",
            "===========================> Rendering remaining 89 images in the queue...\n",
            "===========================> Rendering remaining 15 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 376/376 [00:16<00:00, 22.63it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 191 images in the queue...\n",
            "===========================> Rendering remaining 164 images in the queue...\n",
            "===========================> Rendering remaining 138 images in the queue...\n",
            "===========================> Rendering remaining 111 images in the queue...\n",
            "===========================> Rendering remaining 85 images in the queue...\n",
            "===========================> Rendering remaining 6 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 593/593 [00:32<00:00, 17.99it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 283 images in the queue...\n",
            "===========================> Rendering remaining 257 images in the queue...\n",
            "===========================> Rendering remaining 232 images in the queue...\n",
            "===========================> Rendering remaining 206 images in the queue...\n",
            "===========================> Rendering remaining 180 images in the queue...\n",
            "===========================> Rendering remaining 153 images in the queue...\n",
            "===========================> Rendering remaining 128 images in the queue...\n",
            "===========================> Rendering remaining 103 images in the queue...\n",
            "===========================> Rendering remaining 64 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 426/426 [00:20<00:00, 21.01it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 212 images in the queue...\n",
            "===========================> Rendering remaining 187 images in the queue...\n",
            "===========================> Rendering remaining 162 images in the queue...\n",
            "===========================> Rendering remaining 137 images in the queue...\n",
            "===========================> Rendering remaining 111 images in the queue...\n",
            "===========================> Rendering remaining 88 images in the queue...\n",
            "===========================> Rendering remaining 15 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 506/506 [00:21<00:00, 23.56it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 193 images in the queue...\n",
            "===========================> Rendering remaining 168 images in the queue...\n",
            "===========================> Rendering remaining 143 images in the queue...\n",
            "===========================> Rendering remaining 110 images in the queue...\n",
            "===========================> Rendering remaining 85 images in the queue...\n",
            "===========================> Rendering remaining 20 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 350/350 [00:18<00:00, 18.77it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 158 images in the queue...\n",
            "===========================> Rendering remaining 132 images in the queue...\n",
            "===========================> Rendering remaining 106 images in the queue...\n",
            "===========================> Rendering remaining 70 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 299/299 [00:12<00:00, 23.88it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 160 images in the queue...\n",
            "===========================> Rendering remaining 135 images in the queue...\n",
            "===========================> Rendering remaining 111 images in the queue...\n",
            "===========================> Rendering remaining 86 images in the queue...\n",
            "===========================> Rendering remaining 9 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 378/378 [00:17<00:00, 21.58it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 195 images in the queue...\n",
            "===========================> Rendering remaining 170 images in the queue...\n",
            "===========================> Rendering remaining 145 images in the queue...\n",
            "===========================> Rendering remaining 119 images in the queue...\n",
            "===========================> Rendering remaining 93 images in the queue...\n",
            "===========================> Rendering remaining 32 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 317/317 [00:12<00:00, 25.40it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 187 images in the queue...\n",
            "===========================> Rendering remaining 164 images in the queue...\n",
            "===========================> Rendering remaining 142 images in the queue...\n",
            "===========================> Rendering remaining 121 images in the queue...\n",
            "===========================> Rendering remaining 101 images in the queue...\n",
            "===========================> Rendering remaining 61 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 290/290 [00:10<00:00, 28.50it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 178 images in the queue...\n",
            "===========================> Rendering remaining 155 images in the queue...\n",
            "===========================> Rendering remaining 131 images in the queue...\n",
            "===========================> Rendering remaining 107 images in the queue...\n",
            "===========================> Rendering remaining 76 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 295/295 [00:11<00:00, 25.33it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 159 images in the queue...\n",
            "===========================> Rendering remaining 135 images in the queue...\n",
            "===========================> Rendering remaining 111 images in the queue...\n",
            "===========================> Rendering remaining 85 images in the queue...\n",
            "===========================> Rendering remaining 6 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 250/250 [00:07<00:00, 34.42it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 157 images in the queue...\n",
            "===========================> Rendering remaining 134 images in the queue...\n",
            "===========================> Rendering remaining 110 images in the queue...\n",
            "===========================> Rendering remaining 90 images in the queue...\n",
            "===========================> Rendering remaining 21 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 267/267 [00:13<00:00, 19.53it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 126 images in the queue...\n",
            "===========================> Rendering remaining 101 images in the queue...\n",
            "===========================> Rendering remaining 58 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 424/424 [00:19<00:00, 21.85it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 135 images in the queue...\n",
            "===========================> Rendering remaining 110 images in the queue...\n",
            "===========================> Rendering remaining 85 images in the queue...\n",
            "===========================> Rendering remaining 20 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 270/270 [00:09<00:00, 27.05it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 148 images in the queue...\n",
            "===========================> Rendering remaining 122 images in the queue...\n",
            "===========================> Rendering remaining 96 images in the queue...\n",
            "===========================> Rendering remaining 42 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 494/494 [00:29<00:00, 16.74it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 224 images in the queue...\n",
            "===========================> Rendering remaining 201 images in the queue...\n",
            "===========================> Rendering remaining 176 images in the queue...\n",
            "===========================> Rendering remaining 151 images in the queue...\n",
            "===========================> Rendering remaining 127 images in the queue...\n",
            "===========================> Rendering remaining 101 images in the queue...\n",
            "===========================> Rendering remaining 60 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 300/300 [00:15<00:00, 19.25it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 137 images in the queue...\n",
            "===========================> Rendering remaining 112 images in the queue...\n",
            "===========================> Rendering remaining 86 images in the queue...\n",
            "===========================> Rendering remaining 12 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 311/311 [00:13<00:00, 22.78it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 166 images in the queue...\n",
            "===========================> Rendering remaining 141 images in the queue...\n",
            "===========================> Rendering remaining 116 images in the queue...\n",
            "===========================> Rendering remaining 91 images in the queue...\n",
            "===========================> Rendering remaining 25 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 273/273 [00:11<00:00, 24.41it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 144 images in the queue...\n",
            "===========================> Rendering remaining 118 images in the queue...\n",
            "===========================> Rendering remaining 93 images in the queue...\n",
            "===========================> Rendering remaining 29 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 346/346 [00:11<00:00, 30.29it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 143 images in the queue...\n",
            "===========================> Rendering remaining 121 images in the queue...\n",
            "===========================> Rendering remaining 97 images in the queue...\n",
            "===========================> Rendering remaining 64 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 295/295 [00:12<00:00, 23.46it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 158 images in the queue...\n",
            "===========================> Rendering remaining 132 images in the queue...\n",
            "===========================> Rendering remaining 107 images in the queue...\n",
            "===========================> Rendering remaining 75 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 287/287 [00:15<00:00, 18.55it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 132 images in the queue...\n",
            "===========================> Rendering remaining 107 images in the queue...\n",
            "===========================> Rendering remaining 74 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 376/376 [00:16<00:00, 22.20it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 208 images in the queue...\n",
            "===========================> Rendering remaining 188 images in the queue...\n",
            "===========================> Rendering remaining 170 images in the queue...\n",
            "===========================> Rendering remaining 151 images in the queue...\n",
            "===========================> Rendering remaining 131 images in the queue...\n",
            "===========================> Rendering remaining 108 images in the queue...\n",
            "===========================> Rendering remaining 82 images in the queue...\n",
            "===========================> Rendering remaining 1 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 372/372 [00:16<00:00, 22.89it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 198 images in the queue...\n",
            "===========================> Rendering remaining 172 images in the queue...\n",
            "===========================> Rendering remaining 146 images in the queue...\n",
            "===========================> Rendering remaining 120 images in the queue...\n",
            "===========================> Rendering remaining 94 images in the queue...\n",
            "===========================> Rendering remaining 32 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 441/441 [00:25<00:00, 17.25it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 201 images in the queue...\n",
            "===========================> Rendering remaining 175 images in the queue...\n",
            "===========================> Rendering remaining 149 images in the queue...\n",
            "===========================> Rendering remaining 123 images in the queue...\n",
            "===========================> Rendering remaining 97 images in the queue...\n",
            "===========================> Rendering remaining 44 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 1033/1033 [00:54<00:00, 18.91it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 495 images in the queue...\n",
            "===========================> Rendering remaining 469 images in the queue...\n",
            "===========================> Rendering remaining 443 images in the queue...\n",
            "===========================> Rendering remaining 416 images in the queue...\n",
            "===========================> Rendering remaining 391 images in the queue...\n",
            "===========================> Rendering remaining 365 images in the queue...\n",
            "===========================> Rendering remaining 340 images in the queue...\n",
            "===========================> Rendering remaining 284 images in the queue...\n",
            "===========================> Rendering remaining 205 images in the queue...\n",
            "===========================> Rendering remaining 127 images in the queue...\n",
            "===========================> Rendering remaining 46 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 302/302 [00:12<00:00, 24.97it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 168 images in the queue...\n",
            "===========================> Rendering remaining 143 images in the queue...\n",
            "===========================> Rendering remaining 118 images in the queue...\n",
            "===========================> Rendering remaining 93 images in the queue...\n",
            "===========================> Rendering remaining 29 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 260/260 [00:07<00:00, 34.07it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 160 images in the queue...\n",
            "===========================> Rendering remaining 137 images in the queue...\n",
            "===========================> Rendering remaining 115 images in the queue...\n",
            "===========================> Rendering remaining 96 images in the queue...\n",
            "===========================> Rendering remaining 42 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 357/357 [00:15<00:00, 22.49it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 185 images in the queue...\n",
            "===========================> Rendering remaining 159 images in the queue...\n",
            "===========================> Rendering remaining 133 images in the queue...\n",
            "===========================> Rendering remaining 108 images in the queue...\n",
            "===========================> Rendering remaining 77 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 945/945 [00:46<00:00, 20.18it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 493 images in the queue...\n",
            "===========================> Rendering remaining 469 images in the queue...\n",
            "===========================> Rendering remaining 444 images in the queue...\n",
            "===========================> Rendering remaining 420 images in the queue...\n",
            "===========================> Rendering remaining 396 images in the queue...\n",
            "===========================> Rendering remaining 372 images in the queue...\n",
            "===========================> Rendering remaining 322 images in the queue...\n",
            "===========================> Rendering remaining 241 images in the queue...\n",
            "===========================> Rendering remaining 160 images in the queue...\n",
            "===========================> Rendering remaining 80 images in the queue...\n",
            "===========================> Rendering remaining 3 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 391/391 [00:17<00:00, 21.97it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 164 images in the queue...\n",
            "===========================> Rendering remaining 122 images in the queue...\n",
            "===========================> Rendering remaining 91 images in the queue...\n",
            "===========================> Rendering remaining 24 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 700/700 [00:28<00:00, 24.54it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 382 images in the queue...\n",
            "===========================> Rendering remaining 356 images in the queue...\n",
            "===========================> Rendering remaining 288 images in the queue...\n",
            "===========================> Rendering remaining 207 images in the queue...\n",
            "===========================> Rendering remaining 125 images in the queue...\n",
            "===========================> Rendering remaining 45 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 1190/1190 [01:22<00:00, 14.40it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 508 images in the queue...\n",
            "===========================> Rendering remaining 482 images in the queue...\n",
            "===========================> Rendering remaining 456 images in the queue...\n",
            "===========================> Rendering remaining 431 images in the queue...\n",
            "===========================> Rendering remaining 405 images in the queue...\n",
            "===========================> Rendering remaining 379 images in the queue...\n",
            "===========================> Rendering remaining 353 images in the queue...\n",
            "===========================> Rendering remaining 326 images in the queue...\n",
            "===========================> Rendering remaining 301 images in the queue...\n",
            "===========================> Rendering remaining 274 images in the queue...\n",
            "===========================> Rendering remaining 249 images in the queue...\n",
            "===========================> Rendering remaining 223 images in the queue...\n",
            "===========================> Rendering remaining 198 images in the queue...\n",
            "===========================> Rendering remaining 174 images in the queue...\n",
            "===========================> Rendering remaining 151 images in the queue...\n",
            "===========================> Rendering remaining 128 images in the queue...\n",
            "===========================> Rendering remaining 104 images in the queue...\n",
            "===========================> Rendering remaining 45 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 654/654 [00:37<00:00, 17.50it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 308 images in the queue...\n",
            "===========================> Rendering remaining 283 images in the queue...\n",
            "===========================> Rendering remaining 257 images in the queue...\n",
            "===========================> Rendering remaining 230 images in the queue...\n",
            "===========================> Rendering remaining 204 images in the queue...\n",
            "===========================> Rendering remaining 177 images in the queue...\n",
            "===========================> Rendering remaining 150 images in the queue...\n",
            "===========================> Rendering remaining 124 images in the queue...\n",
            "===========================> Rendering remaining 100 images in the queue...\n",
            "===========================> Rendering remaining 28 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 1481/1481 [01:48<00:00, 13.62it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 639 images in the queue...\n",
            "===========================> Rendering remaining 614 images in the queue...\n",
            "===========================> Rendering remaining 589 images in the queue...\n",
            "===========================> Rendering remaining 564 images in the queue...\n",
            "===========================> Rendering remaining 538 images in the queue...\n",
            "===========================> Rendering remaining 515 images in the queue...\n",
            "===========================> Rendering remaining 488 images in the queue...\n",
            "===========================> Rendering remaining 466 images in the queue...\n",
            "===========================> Rendering remaining 441 images in the queue...\n",
            "===========================> Rendering remaining 415 images in the queue...\n",
            "===========================> Rendering remaining 392 images in the queue...\n",
            "===========================> Rendering remaining 366 images in the queue...\n",
            "===========================> Rendering remaining 340 images in the queue...\n",
            "===========================> Rendering remaining 317 images in the queue...\n",
            "===========================> Rendering remaining 293 images in the queue...\n",
            "===========================> Rendering remaining 267 images in the queue...\n",
            "===========================> Rendering remaining 243 images in the queue...\n",
            "===========================> Rendering remaining 218 images in the queue...\n",
            "===========================> Rendering remaining 192 images in the queue...\n",
            "===========================> Rendering remaining 170 images in the queue...\n",
            "===========================> Rendering remaining 145 images in the queue...\n",
            "===========================> Rendering remaining 119 images in the queue...\n",
            "===========================> Rendering remaining 87 images in the queue...\n",
            "===========================> Rendering remaining 9 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 455/455 [00:22<00:00, 20.33it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 254 images in the queue...\n",
            "===========================> Rendering remaining 233 images in the queue...\n",
            "===========================> Rendering remaining 213 images in the queue...\n",
            "===========================> Rendering remaining 189 images in the queue...\n",
            "===========================> Rendering remaining 165 images in the queue...\n",
            "===========================> Rendering remaining 141 images in the queue...\n",
            "===========================> Rendering remaining 120 images in the queue...\n",
            "===========================> Rendering remaining 100 images in the queue...\n",
            "===========================> Rendering remaining 31 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 491/491 [00:26<00:00, 18.84it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 298 images in the queue...\n",
            "===========================> Rendering remaining 280 images in the queue...\n",
            "===========================> Rendering remaining 262 images in the queue...\n",
            "===========================> Rendering remaining 244 images in the queue...\n",
            "===========================> Rendering remaining 226 images in the queue...\n",
            "===========================> Rendering remaining 209 images in the queue...\n",
            "===========================> Rendering remaining 190 images in the queue...\n",
            "===========================> Rendering remaining 173 images in the queue...\n",
            "===========================> Rendering remaining 156 images in the queue...\n",
            "===========================> Rendering remaining 138 images in the queue...\n",
            "===========================> Rendering remaining 121 images in the queue...\n",
            "===========================> Rendering remaining 101 images in the queue...\n",
            "===========================> Rendering remaining 35 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 531/531 [00:28<00:00, 18.87it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 271 images in the queue...\n",
            "===========================> Rendering remaining 247 images in the queue...\n",
            "===========================> Rendering remaining 223 images in the queue...\n",
            "===========================> Rendering remaining 199 images in the queue...\n",
            "===========================> Rendering remaining 176 images in the queue...\n",
            "===========================> Rendering remaining 155 images in the queue...\n",
            "===========================> Rendering remaining 135 images in the queue...\n",
            "===========================> Rendering remaining 118 images in the queue...\n",
            "===========================> Rendering remaining 101 images in the queue...\n",
            "===========================> Rendering remaining 41 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 309/309 [00:12<00:00, 24.75it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 171 images in the queue...\n",
            "===========================> Rendering remaining 145 images in the queue...\n",
            "===========================> Rendering remaining 119 images in the queue...\n",
            "===========================> Rendering remaining 86 images in the queue...\n",
            "===========================> Rendering remaining 5 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 595/595 [00:38<00:00, 15.32it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 257 images in the queue...\n",
            "===========================> Rendering remaining 231 images in the queue...\n",
            "===========================> Rendering remaining 205 images in the queue...\n",
            "===========================> Rendering remaining 179 images in the queue...\n",
            "===========================> Rendering remaining 153 images in the queue...\n",
            "===========================> Rendering remaining 128 images in the queue...\n",
            "===========================> Rendering remaining 102 images in the queue...\n",
            "===========================> Rendering remaining 33 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 322/322 [00:13<00:00, 23.55it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 169 images in the queue...\n",
            "===========================> Rendering remaining 144 images in the queue...\n",
            "===========================> Rendering remaining 117 images in the queue...\n",
            "===========================> Rendering remaining 91 images in the queue...\n",
            "===========================> Rendering remaining 22 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 358/358 [00:15<00:00, 22.46it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 190 images in the queue...\n",
            "===========================> Rendering remaining 165 images in the queue...\n",
            "===========================> Rendering remaining 139 images in the queue...\n",
            "===========================> Rendering remaining 114 images in the queue...\n",
            "===========================> Rendering remaining 88 images in the queue...\n",
            "===========================> Rendering remaining 16 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 398/398 [00:18<00:00, 22.06it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 204 images in the queue...\n",
            "===========================> Rendering remaining 178 images in the queue...\n",
            "===========================> Rendering remaining 153 images in the queue...\n",
            "===========================> Rendering remaining 126 images in the queue...\n",
            "===========================> Rendering remaining 101 images in the queue...\n",
            "===========================> Rendering remaining 56 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 294/294 [00:09<00:00, 29.47it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 173 images in the queue...\n",
            "===========================> Rendering remaining 147 images in the queue...\n",
            "===========================> Rendering remaining 126 images in the queue...\n",
            "===========================> Rendering remaining 101 images in the queue...\n",
            "===========================> Rendering remaining 60 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 195/195 [00:04<00:00, 42.20it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 115 images in the queue...\n",
            "===========================> Rendering remaining 89 images in the queue...\n",
            "===========================> Rendering remaining 19 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 296/296 [00:12<00:00, 23.68it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 161 images in the queue...\n",
            "===========================> Rendering remaining 135 images in the queue...\n",
            "===========================> Rendering remaining 110 images in the queue...\n",
            "===========================> Rendering remaining 83 images in the queue...\n",
            "===========================> Rendering remaining 1 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 376/376 [00:13<00:00, 27.83it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 159 images in the queue...\n",
            "===========================> Rendering remaining 134 images in the queue...\n",
            "===========================> Rendering remaining 108 images in the queue...\n",
            "===========================> Rendering remaining 81 images in the queue...\n",
            "===========================> Rendering remaining 1 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 379/379 [00:16<00:00, 23.01it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 197 images in the queue...\n",
            "===========================> Rendering remaining 171 images in the queue...\n",
            "===========================> Rendering remaining 145 images in the queue...\n",
            "===========================> Rendering remaining 120 images in the queue...\n",
            "===========================> Rendering remaining 94 images in the queue...\n",
            "===========================> Rendering remaining 33 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 301/301 [00:16<00:00, 18.12it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 167 images in the queue...\n",
            "===========================> Rendering remaining 147 images in the queue...\n",
            "===========================> Rendering remaining 127 images in the queue...\n",
            "===========================> Rendering remaining 105 images in the queue...\n",
            "===========================> Rendering remaining 85 images in the queue...\n",
            "===========================> Rendering remaining 7 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 290/290 [00:11<00:00, 25.27it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 161 images in the queue...\n",
            "===========================> Rendering remaining 136 images in the queue...\n",
            "===========================> Rendering remaining 110 images in the queue...\n",
            "===========================> Rendering remaining 85 images in the queue...\n",
            "===========================> Rendering remaining 5 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 188/188 [00:05<00:00, 36.71it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 114 images in the queue...\n",
            "===========================> Rendering remaining 89 images in the queue...\n",
            "===========================> Rendering remaining 18 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 322/322 [00:13<00:00, 23.19it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 181 images in the queue...\n",
            "===========================> Rendering remaining 159 images in the queue...\n",
            "===========================> Rendering remaining 137 images in the queue...\n",
            "===========================> Rendering remaining 112 images in the queue...\n",
            "===========================> Rendering remaining 89 images in the queue...\n",
            "===========================> Rendering remaining 17 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 278/278 [00:11<00:00, 25.03it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 157 images in the queue...\n",
            "===========================> Rendering remaining 131 images in the queue...\n",
            "===========================> Rendering remaining 107 images in the queue...\n",
            "===========================> Rendering remaining 78 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 388/388 [00:17<00:00, 22.19it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 206 images in the queue...\n",
            "===========================> Rendering remaining 181 images in the queue...\n",
            "===========================> Rendering remaining 155 images in the queue...\n",
            "===========================> Rendering remaining 130 images in the queue...\n",
            "===========================> Rendering remaining 104 images in the queue...\n",
            "===========================> Rendering remaining 67 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 411/411 [00:23<00:00, 17.48it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 186 images in the queue...\n",
            "===========================> Rendering remaining 160 images in the queue...\n",
            "===========================> Rendering remaining 135 images in the queue...\n",
            "===========================> Rendering remaining 110 images in the queue...\n",
            "===========================> Rendering remaining 83 images in the queue...\n",
            "===========================> Rendering remaining 3 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 376/376 [00:16<00:00, 22.38it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 203 images in the queue...\n",
            "===========================> Rendering remaining 178 images in the queue...\n",
            "===========================> Rendering remaining 153 images in the queue...\n",
            "===========================> Rendering remaining 128 images in the queue...\n",
            "===========================> Rendering remaining 102 images in the queue...\n",
            "===========================> Rendering remaining 61 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 374/374 [00:14<00:00, 25.43it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 159 images in the queue...\n",
            "===========================> Rendering remaining 133 images in the queue...\n",
            "===========================> Rendering remaining 107 images in the queue...\n",
            "===========================> Rendering remaining 71 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 403/403 [00:19<00:00, 21.13it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 202 images in the queue...\n",
            "===========================> Rendering remaining 174 images in the queue...\n",
            "===========================> Rendering remaining 147 images in the queue...\n",
            "===========================> Rendering remaining 118 images in the queue...\n",
            "===========================> Rendering remaining 90 images in the queue...\n",
            "===========================> Rendering remaining 26 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 360/360 [00:13<00:00, 27.49it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 182 images in the queue...\n",
            "===========================> Rendering remaining 156 images in the queue...\n",
            "===========================> Rendering remaining 130 images in the queue...\n",
            "===========================> Rendering remaining 86 images in the queue...\n",
            "===========================> Rendering remaining 5 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 351/351 [00:15<00:00, 23.05it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 182 images in the queue...\n",
            "===========================> Rendering remaining 156 images in the queue...\n",
            "===========================> Rendering remaining 131 images in the queue...\n",
            "===========================> Rendering remaining 106 images in the queue...\n",
            "===========================> Rendering remaining 70 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 334/334 [00:13<00:00, 24.13it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 182 images in the queue...\n",
            "===========================> Rendering remaining 156 images in the queue...\n",
            "===========================> Rendering remaining 131 images in the queue...\n",
            "===========================> Rendering remaining 106 images in the queue...\n",
            "===========================> Rendering remaining 71 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 284/284 [00:10<00:00, 25.92it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 154 images in the queue...\n",
            "===========================> Rendering remaining 129 images in the queue...\n",
            "===========================> Rendering remaining 103 images in the queue...\n",
            "===========================> Rendering remaining 61 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 383/383 [00:17<00:00, 22.04it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 186 images in the queue...\n",
            "===========================> Rendering remaining 160 images in the queue...\n",
            "===========================> Rendering remaining 134 images in the queue...\n",
            "===========================> Rendering remaining 108 images in the queue...\n",
            "===========================> Rendering remaining 78 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "  0% 0/340 [00:00<?, ?it/s]Try to use other video encoders...\n",
            "100% 340/340 [00:12<00:00, 27.99it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 172 images in the queue...\n",
            "===========================> Rendering remaining 151 images in the queue...\n",
            "===========================> Rendering remaining 129 images in the queue...\n",
            "===========================> Rendering remaining 109 images in the queue...\n",
            "===========================> Rendering remaining 87 images in the queue...\n",
            "===========================> Rendering remaining 16 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 331/331 [00:14<00:00, 23.17it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 175 images in the queue...\n",
            "===========================> Rendering remaining 149 images in the queue...\n",
            "===========================> Rendering remaining 124 images in the queue...\n",
            "===========================> Rendering remaining 98 images in the queue...\n",
            "===========================> Rendering remaining 51 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 391/391 [00:18<00:00, 21.31it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 201 images in the queue...\n",
            "===========================> Rendering remaining 177 images in the queue...\n",
            "===========================> Rendering remaining 152 images in the queue...\n",
            "===========================> Rendering remaining 126 images in the queue...\n",
            "===========================> Rendering remaining 101 images in the queue...\n",
            "===========================> Rendering remaining 59 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 445/445 [00:20<00:00, 21.44it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 226 images in the queue...\n",
            "===========================> Rendering remaining 198 images in the queue...\n",
            "===========================> Rendering remaining 172 images in the queue...\n",
            "===========================> Rendering remaining 149 images in the queue...\n",
            "===========================> Rendering remaining 123 images in the queue...\n",
            "===========================> Rendering remaining 97 images in the queue...\n",
            "===========================> Rendering remaining 39 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 419/419 [00:18<00:00, 22.23it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 220 images in the queue...\n",
            "===========================> Rendering remaining 196 images in the queue...\n",
            "===========================> Rendering remaining 170 images in the queue...\n",
            "===========================> Rendering remaining 145 images in the queue...\n",
            "===========================> Rendering remaining 120 images in the queue...\n",
            "===========================> Rendering remaining 95 images in the queue...\n",
            "===========================> Rendering remaining 37 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 358/358 [00:14<00:00, 23.88it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 186 images in the queue...\n",
            "===========================> Rendering remaining 161 images in the queue...\n",
            "===========================> Rendering remaining 135 images in the queue...\n",
            "===========================> Rendering remaining 110 images in the queue...\n",
            "===========================> Rendering remaining 84 images in the queue...\n",
            "===========================> Rendering remaining 5 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 553/553 [00:27<00:00, 19.90it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 254 images in the queue...\n",
            "===========================> Rendering remaining 234 images in the queue...\n",
            "===========================> Rendering remaining 214 images in the queue...\n",
            "===========================> Rendering remaining 193 images in the queue...\n",
            "===========================> Rendering remaining 173 images in the queue...\n",
            "===========================> Rendering remaining 151 images in the queue...\n",
            "===========================> Rendering remaining 127 images in the queue...\n",
            "===========================> Rendering remaining 108 images in the queue...\n",
            "===========================> Rendering remaining 89 images in the queue...\n",
            "===========================> Rendering remaining 37 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 446/446 [00:17<00:00, 25.11it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 210 images in the queue...\n",
            "===========================> Rendering remaining 182 images in the queue...\n",
            "===========================> Rendering remaining 155 images in the queue...\n",
            "===========================> Rendering remaining 127 images in the queue...\n",
            "===========================> Rendering remaining 93 images in the queue...\n",
            "===========================> Rendering remaining 24 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 561/561 [00:29<00:00, 19.05it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 264 images in the queue...\n",
            "===========================> Rendering remaining 239 images in the queue...\n",
            "===========================> Rendering remaining 207 images in the queue...\n",
            "===========================> Rendering remaining 182 images in the queue...\n",
            "===========================> Rendering remaining 158 images in the queue...\n",
            "===========================> Rendering remaining 133 images in the queue...\n",
            "===========================> Rendering remaining 107 images in the queue...\n",
            "===========================> Rendering remaining 77 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 250/250 [00:09<00:00, 25.51it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 137 images in the queue...\n",
            "===========================> Rendering remaining 112 images in the queue...\n",
            "===========================> Rendering remaining 86 images in the queue...\n",
            "===========================> Rendering remaining 8 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 404/404 [00:18<00:00, 21.91it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 199 images in the queue...\n",
            "===========================> Rendering remaining 174 images in the queue...\n",
            "===========================> Rendering remaining 150 images in the queue...\n",
            "===========================> Rendering remaining 123 images in the queue...\n",
            "===========================> Rendering remaining 97 images in the queue...\n",
            "===========================> Rendering remaining 43 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 424/424 [00:19<00:00, 21.34it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 218 images in the queue...\n",
            "===========================> Rendering remaining 192 images in the queue...\n",
            "===========================> Rendering remaining 166 images in the queue...\n",
            "===========================> Rendering remaining 140 images in the queue...\n",
            "===========================> Rendering remaining 114 images in the queue...\n",
            "===========================> Rendering remaining 89 images in the queue...\n",
            "===========================> Rendering remaining 18 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 515/515 [00:28<00:00, 17.77it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 325 images in the queue...\n",
            "===========================> Rendering remaining 308 images in the queue...\n",
            "===========================> Rendering remaining 291 images in the queue...\n",
            "===========================> Rendering remaining 273 images in the queue...\n",
            "===========================> Rendering remaining 256 images in the queue...\n",
            "===========================> Rendering remaining 239 images in the queue...\n",
            "===========================> Rendering remaining 222 images in the queue...\n",
            "===========================> Rendering remaining 205 images in the queue...\n",
            "===========================> Rendering remaining 189 images in the queue...\n",
            "===========================> Rendering remaining 172 images in the queue...\n",
            "===========================> Rendering remaining 155 images in the queue...\n",
            "===========================> Rendering remaining 138 images in the queue...\n",
            "===========================> Rendering remaining 120 images in the queue...\n",
            "===========================> Rendering remaining 103 images in the queue...\n",
            "===========================> Rendering remaining 86 images in the queue...\n",
            "===========================> Rendering remaining 12 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 591/591 [00:31<00:00, 18.57it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 264 images in the queue...\n",
            "===========================> Rendering remaining 237 images in the queue...\n",
            "===========================> Rendering remaining 212 images in the queue...\n",
            "===========================> Rendering remaining 186 images in the queue...\n",
            "===========================> Rendering remaining 160 images in the queue...\n",
            "===========================> Rendering remaining 134 images in the queue...\n",
            "===========================> Rendering remaining 109 images in the queue...\n",
            "===========================> Rendering remaining 80 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 495/495 [00:25<00:00, 19.80it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 249 images in the queue...\n",
            "===========================> Rendering remaining 223 images in the queue...\n",
            "===========================> Rendering remaining 197 images in the queue...\n",
            "===========================> Rendering remaining 172 images in the queue...\n",
            "===========================> Rendering remaining 146 images in the queue...\n",
            "===========================> Rendering remaining 121 images in the queue...\n",
            "===========================> Rendering remaining 96 images in the queue...\n",
            "===========================> Rendering remaining 39 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 292/292 [00:11<00:00, 24.74it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 148 images in the queue...\n",
            "===========================> Rendering remaining 123 images in the queue...\n",
            "===========================> Rendering remaining 98 images in the queue...\n",
            "===========================> Rendering remaining 46 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 545/545 [00:29<00:00, 18.49it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 266 images in the queue...\n",
            "===========================> Rendering remaining 241 images in the queue...\n",
            "===========================> Rendering remaining 214 images in the queue...\n",
            "===========================> Rendering remaining 188 images in the queue...\n",
            "===========================> Rendering remaining 162 images in the queue...\n",
            "===========================> Rendering remaining 137 images in the queue...\n",
            "===========================> Rendering remaining 112 images in the queue...\n",
            "===========================> Rendering remaining 87 images in the queue...\n",
            "===========================> Rendering remaining 15 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 421/421 [00:19<00:00, 21.06it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 224 images in the queue...\n",
            "===========================> Rendering remaining 200 images in the queue...\n",
            "===========================> Rendering remaining 175 images in the queue...\n",
            "===========================> Rendering remaining 149 images in the queue...\n",
            "===========================> Rendering remaining 124 images in the queue...\n",
            "===========================> Rendering remaining 100 images in the queue...\n",
            "===========================> Rendering remaining 53 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 529/529 [00:29<00:00, 18.11it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 254 images in the queue...\n",
            "===========================> Rendering remaining 228 images in the queue...\n",
            "===========================> Rendering remaining 202 images in the queue...\n",
            "===========================> Rendering remaining 176 images in the queue...\n",
            "===========================> Rendering remaining 150 images in the queue...\n",
            "===========================> Rendering remaining 125 images in the queue...\n",
            "===========================> Rendering remaining 100 images in the queue...\n",
            "===========================> Rendering remaining 54 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 565/565 [00:31<00:00, 17.99it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 266 images in the queue...\n",
            "===========================> Rendering remaining 239 images in the queue...\n",
            "===========================> Rendering remaining 213 images in the queue...\n",
            "===========================> Rendering remaining 186 images in the queue...\n",
            "===========================> Rendering remaining 159 images in the queue...\n",
            "===========================> Rendering remaining 132 images in the queue...\n",
            "===========================> Rendering remaining 107 images in the queue...\n",
            "===========================> Rendering remaining 76 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 493/493 [00:25<00:00, 19.70it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 246 images in the queue...\n",
            "===========================> Rendering remaining 221 images in the queue...\n",
            "===========================> Rendering remaining 196 images in the queue...\n",
            "===========================> Rendering remaining 171 images in the queue...\n",
            "===========================> Rendering remaining 146 images in the queue...\n",
            "===========================> Rendering remaining 121 images in the queue...\n",
            "===========================> Rendering remaining 96 images in the queue...\n",
            "===========================> Rendering remaining 43 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 567/567 [00:35<00:00, 15.91it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 240 images in the queue...\n",
            "===========================> Rendering remaining 215 images in the queue...\n",
            "===========================> Rendering remaining 189 images in the queue...\n",
            "===========================> Rendering remaining 164 images in the queue...\n",
            "===========================> Rendering remaining 138 images in the queue...\n",
            "===========================> Rendering remaining 112 images in the queue...\n",
            "===========================> Rendering remaining 87 images in the queue...\n",
            "===========================> Rendering remaining 10 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 493/493 [00:23<00:00, 21.00it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 239 images in the queue...\n",
            "===========================> Rendering remaining 209 images in the queue...\n",
            "===========================> Rendering remaining 183 images in the queue...\n",
            "===========================> Rendering remaining 156 images in the queue...\n",
            "===========================> Rendering remaining 131 images in the queue...\n",
            "===========================> Rendering remaining 106 images in the queue...\n",
            "===========================> Rendering remaining 70 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 505/505 [00:24<00:00, 20.43it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 250 images in the queue...\n",
            "===========================> Rendering remaining 224 images in the queue...\n",
            "===========================> Rendering remaining 199 images in the queue...\n",
            "===========================> Rendering remaining 173 images in the queue...\n",
            "===========================> Rendering remaining 148 images in the queue...\n",
            "===========================> Rendering remaining 122 images in the queue...\n",
            "===========================> Rendering remaining 96 images in the queue...\n",
            "===========================> Rendering remaining 40 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "  0% 0/693 [00:00<?, ?it/s]Try to use other video encoders...\n",
            "100% 693/693 [00:45<00:00, 15.10it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 296 images in the queue...\n",
            "===========================> Rendering remaining 271 images in the queue...\n",
            "===========================> Rendering remaining 246 images in the queue...\n",
            "===========================> Rendering remaining 221 images in the queue...\n",
            "===========================> Rendering remaining 197 images in the queue...\n",
            "===========================> Rendering remaining 171 images in the queue...\n",
            "===========================> Rendering remaining 146 images in the queue...\n",
            "===========================> Rendering remaining 121 images in the queue...\n",
            "===========================> Rendering remaining 97 images in the queue...\n",
            "===========================> Rendering remaining 59 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 345/345 [00:14<00:00, 24.17it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 187 images in the queue...\n",
            "===========================> Rendering remaining 161 images in the queue...\n",
            "===========================> Rendering remaining 137 images in the queue...\n",
            "===========================> Rendering remaining 113 images in the queue...\n",
            "===========================> Rendering remaining 88 images in the queue...\n",
            "===========================> Rendering remaining 13 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 657/657 [00:38<00:00, 16.95it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 305 images in the queue...\n",
            "===========================> Rendering remaining 280 images in the queue...\n",
            "===========================> Rendering remaining 254 images in the queue...\n",
            "===========================> Rendering remaining 229 images in the queue...\n",
            "===========================> Rendering remaining 203 images in the queue...\n",
            "===========================> Rendering remaining 178 images in the queue...\n",
            "===========================> Rendering remaining 152 images in the queue...\n",
            "===========================> Rendering remaining 127 images in the queue...\n",
            "===========================> Rendering remaining 102 images in the queue...\n",
            "===========================> Rendering remaining 59 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 376/376 [00:15<00:00, 23.68it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 201 images in the queue...\n",
            "===========================> Rendering remaining 175 images in the queue...\n",
            "===========================> Rendering remaining 149 images in the queue...\n",
            "===========================> Rendering remaining 125 images in the queue...\n",
            "===========================> Rendering remaining 99 images in the queue...\n",
            "===========================> Rendering remaining 50 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 499/499 [00:24<00:00, 20.10it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 254 images in the queue...\n",
            "===========================> Rendering remaining 229 images in the queue...\n",
            "===========================> Rendering remaining 203 images in the queue...\n",
            "===========================> Rendering remaining 178 images in the queue...\n",
            "===========================> Rendering remaining 153 images in the queue...\n",
            "===========================> Rendering remaining 128 images in the queue...\n",
            "===========================> Rendering remaining 103 images in the queue...\n",
            "===========================> Rendering remaining 66 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 412/412 [00:18<00:00, 21.76it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 207 images in the queue...\n",
            "===========================> Rendering remaining 181 images in the queue...\n",
            "===========================> Rendering remaining 156 images in the queue...\n",
            "===========================> Rendering remaining 131 images in the queue...\n",
            "===========================> Rendering remaining 105 images in the queue...\n",
            "===========================> Rendering remaining 73 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 687/687 [00:40<00:00, 16.84it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 323 images in the queue...\n",
            "===========================> Rendering remaining 298 images in the queue...\n",
            "===========================> Rendering remaining 273 images in the queue...\n",
            "===========================> Rendering remaining 247 images in the queue...\n",
            "===========================> Rendering remaining 222 images in the queue...\n",
            "===========================> Rendering remaining 197 images in the queue...\n",
            "===========================> Rendering remaining 172 images in the queue...\n",
            "===========================> Rendering remaining 147 images in the queue...\n",
            "===========================> Rendering remaining 122 images in the queue...\n",
            "===========================> Rendering remaining 97 images in the queue...\n",
            "===========================> Rendering remaining 44 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 510/510 [00:26<00:00, 19.42it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 252 images in the queue...\n",
            "===========================> Rendering remaining 226 images in the queue...\n",
            "===========================> Rendering remaining 200 images in the queue...\n",
            "===========================> Rendering remaining 175 images in the queue...\n",
            "===========================> Rendering remaining 150 images in the queue...\n",
            "===========================> Rendering remaining 125 images in the queue...\n",
            "===========================> Rendering remaining 98 images in the queue...\n",
            "===========================> Rendering remaining 50 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 424/424 [00:19<00:00, 21.87it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 225 images in the queue...\n",
            "===========================> Rendering remaining 202 images in the queue...\n",
            "===========================> Rendering remaining 176 images in the queue...\n",
            "===========================> Rendering remaining 152 images in the queue...\n",
            "===========================> Rendering remaining 127 images in the queue...\n",
            "===========================> Rendering remaining 102 images in the queue...\n",
            "===========================> Rendering remaining 62 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 277/277 [00:10<00:00, 27.62it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 192 images in the queue...\n",
            "===========================> Rendering remaining 169 images in the queue...\n",
            "===========================> Rendering remaining 149 images in the queue...\n",
            "===========================> Rendering remaining 134 images in the queue...\n",
            "===========================> Rendering remaining 119 images in the queue...\n",
            "===========================> Rendering remaining 100 images in the queue...\n",
            "===========================> Rendering remaining 84 images in the queue...\n",
            "===========================> Rendering remaining 4 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 557/557 [00:30<00:00, 18.36it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 270 images in the queue...\n",
            "===========================> Rendering remaining 244 images in the queue...\n",
            "===========================> Rendering remaining 218 images in the queue...\n",
            "===========================> Rendering remaining 193 images in the queue...\n",
            "===========================> Rendering remaining 168 images in the queue...\n",
            "===========================> Rendering remaining 142 images in the queue...\n",
            "===========================> Rendering remaining 117 images in the queue...\n",
            "===========================> Rendering remaining 91 images in the queue...\n",
            "===========================> Rendering remaining 28 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "  0% 0/400 [00:00<?, ?it/s]Try to use other video encoders...\n",
            "100% 400/400 [00:17<00:00, 22.44it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 208 images in the queue...\n",
            "===========================> Rendering remaining 183 images in the queue...\n",
            "===========================> Rendering remaining 159 images in the queue...\n",
            "===========================> Rendering remaining 134 images in the queue...\n",
            "===========================> Rendering remaining 109 images in the queue...\n",
            "===========================> Rendering remaining 80 images in the queue...\n",
            "===========================> Rendering remaining 1 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 331/331 [00:13<00:00, 24.12it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 187 images in the queue...\n",
            "===========================> Rendering remaining 162 images in the queue...\n",
            "===========================> Rendering remaining 139 images in the queue...\n",
            "===========================> Rendering remaining 116 images in the queue...\n",
            "===========================> Rendering remaining 92 images in the queue...\n",
            "===========================> Rendering remaining 27 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 232/232 [00:07<00:00, 31.83it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 140 images in the queue...\n",
            "===========================> Rendering remaining 116 images in the queue...\n",
            "===========================> Rendering remaining 94 images in the queue...\n",
            "===========================> Rendering remaining 46 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 330/330 [00:14<00:00, 23.38it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 218 images in the queue...\n",
            "===========================> Rendering remaining 200 images in the queue...\n",
            "===========================> Rendering remaining 180 images in the queue...\n",
            "===========================> Rendering remaining 161 images in the queue...\n",
            "===========================> Rendering remaining 143 images in the queue...\n",
            "===========================> Rendering remaining 125 images in the queue...\n",
            "===========================> Rendering remaining 106 images in the queue...\n",
            "===========================> Rendering remaining 88 images in the queue...\n",
            "===========================> Rendering remaining 21 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 330/330 [00:13<00:00, 24.16it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 190 images in the queue...\n",
            "===========================> Rendering remaining 165 images in the queue...\n",
            "===========================> Rendering remaining 141 images in the queue...\n",
            "===========================> Rendering remaining 116 images in the queue...\n",
            "===========================> Rendering remaining 92 images in the queue...\n",
            "===========================> Rendering remaining 25 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 328/328 [00:17<00:00, 18.52it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 161 images in the queue...\n",
            "===========================> Rendering remaining 136 images in the queue...\n",
            "===========================> Rendering remaining 111 images in the queue...\n",
            "===========================> Rendering remaining 87 images in the queue...\n",
            "===========================> Rendering remaining 10 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 285/285 [00:14<00:00, 19.01it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 132 images in the queue...\n",
            "===========================> Rendering remaining 107 images in the queue...\n",
            "===========================> Rendering remaining 74 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 356/356 [00:15<00:00, 23.14it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 191 images in the queue...\n",
            "===========================> Rendering remaining 167 images in the queue...\n",
            "===========================> Rendering remaining 141 images in the queue...\n",
            "===========================> Rendering remaining 116 images in the queue...\n",
            "===========================> Rendering remaining 91 images in the queue...\n",
            "===========================> Rendering remaining 27 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 300/300 [00:09<00:00, 30.34it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 187 images in the queue...\n",
            "===========================> Rendering remaining 167 images in the queue...\n",
            "===========================> Rendering remaining 146 images in the queue...\n",
            "===========================> Rendering remaining 130 images in the queue...\n",
            "===========================> Rendering remaining 109 images in the queue...\n",
            "===========================> Rendering remaining 90 images in the queue...\n",
            "===========================> Rendering remaining 30 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 653/653 [00:36<00:00, 17.75it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 336 images in the queue...\n",
            "===========================> Rendering remaining 317 images in the queue...\n",
            "===========================> Rendering remaining 298 images in the queue...\n",
            "===========================> Rendering remaining 282 images in the queue...\n",
            "===========================> Rendering remaining 266 images in the queue...\n",
            "===========================> Rendering remaining 250 images in the queue...\n",
            "===========================> Rendering remaining 233 images in the queue...\n",
            "===========================> Rendering remaining 216 images in the queue...\n",
            "===========================> Rendering remaining 198 images in the queue...\n",
            "===========================> Rendering remaining 179 images in the queue...\n",
            "===========================> Rendering remaining 159 images in the queue...\n",
            "===========================> Rendering remaining 140 images in the queue...\n",
            "===========================> Rendering remaining 121 images in the queue...\n",
            "===========================> Rendering remaining 96 images in the queue...\n",
            "===========================> Rendering remaining 15 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 341/341 [00:14<00:00, 23.66it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 188 images in the queue...\n",
            "===========================> Rendering remaining 163 images in the queue...\n",
            "===========================> Rendering remaining 137 images in the queue...\n",
            "===========================> Rendering remaining 111 images in the queue...\n",
            "===========================> Rendering remaining 85 images in the queue...\n",
            "===========================> Rendering remaining 6 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 509/509 [00:21<00:00, 23.73it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 207 images in the queue...\n",
            "===========================> Rendering remaining 181 images in the queue...\n",
            "===========================> Rendering remaining 155 images in the queue...\n",
            "===========================> Rendering remaining 128 images in the queue...\n",
            "===========================> Rendering remaining 102 images in the queue...\n",
            "===========================> Rendering remaining 73 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 645/645 [00:30<00:00, 21.03it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 283 images in the queue...\n",
            "===========================> Rendering remaining 257 images in the queue...\n",
            "===========================> Rendering remaining 232 images in the queue...\n",
            "===========================> Rendering remaining 207 images in the queue...\n",
            "===========================> Rendering remaining 182 images in the queue...\n",
            "===========================> Rendering remaining 158 images in the queue...\n",
            "===========================> Rendering remaining 132 images in the queue...\n",
            "===========================> Rendering remaining 107 images in the queue...\n",
            "===========================> Rendering remaining 34 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 227/227 [00:08<00:00, 26.00it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 131 images in the queue...\n",
            "===========================> Rendering remaining 106 images in the queue...\n",
            "===========================> Rendering remaining 71 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 802/802 [00:50<00:00, 15.82it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 354 images in the queue...\n",
            "===========================> Rendering remaining 328 images in the queue...\n",
            "===========================> Rendering remaining 302 images in the queue...\n",
            "===========================> Rendering remaining 276 images in the queue...\n",
            "===========================> Rendering remaining 250 images in the queue...\n",
            "===========================> Rendering remaining 224 images in the queue...\n",
            "===========================> Rendering remaining 199 images in the queue...\n",
            "===========================> Rendering remaining 175 images in the queue...\n",
            "===========================> Rendering remaining 149 images in the queue...\n",
            "===========================> Rendering remaining 124 images in the queue...\n",
            "===========================> Rendering remaining 97 images in the queue...\n",
            "===========================> Rendering remaining 45 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 351/351 [00:14<00:00, 25.00it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 201 images in the queue...\n",
            "===========================> Rendering remaining 177 images in the queue...\n",
            "===========================> Rendering remaining 152 images in the queue...\n",
            "===========================> Rendering remaining 129 images in the queue...\n",
            "===========================> Rendering remaining 104 images in the queue...\n",
            "===========================> Rendering remaining 66 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 616/616 [00:28<00:00, 21.53it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 266 images in the queue...\n",
            "===========================> Rendering remaining 241 images in the queue...\n",
            "===========================> Rendering remaining 216 images in the queue...\n",
            "===========================> Rendering remaining 190 images in the queue...\n",
            "===========================> Rendering remaining 165 images in the queue...\n",
            "===========================> Rendering remaining 141 images in the queue...\n",
            "===========================> Rendering remaining 116 images in the queue...\n",
            "===========================> Rendering remaining 64 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 293/293 [00:10<00:00, 26.92it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 176 images in the queue...\n",
            "===========================> Rendering remaining 151 images in the queue...\n",
            "===========================> Rendering remaining 127 images in the queue...\n",
            "===========================> Rendering remaining 101 images in the queue...\n",
            "===========================> Rendering remaining 56 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 395/395 [00:16<00:00, 23.74it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 207 images in the queue...\n",
            "===========================> Rendering remaining 180 images in the queue...\n",
            "===========================> Rendering remaining 154 images in the queue...\n",
            "===========================> Rendering remaining 128 images in the queue...\n",
            "===========================> Rendering remaining 101 images in the queue...\n",
            "===========================> Rendering remaining 53 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 294/294 [00:10<00:00, 28.03it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 167 images in the queue...\n",
            "===========================> Rendering remaining 144 images in the queue...\n",
            "===========================> Rendering remaining 121 images in the queue...\n",
            "===========================> Rendering remaining 95 images in the queue...\n",
            "===========================> Rendering remaining 38 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 357/357 [00:15<00:00, 23.35it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 188 images in the queue...\n",
            "===========================> Rendering remaining 163 images in the queue...\n",
            "===========================> Rendering remaining 137 images in the queue...\n",
            "===========================> Rendering remaining 111 images in the queue...\n",
            "===========================> Rendering remaining 85 images in the queue...\n",
            "===========================> Rendering remaining 5 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 396/396 [00:17<00:00, 22.82it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 204 images in the queue...\n",
            "===========================> Rendering remaining 178 images in the queue...\n",
            "===========================> Rendering remaining 153 images in the queue...\n",
            "===========================> Rendering remaining 127 images in the queue...\n",
            "===========================> Rendering remaining 101 images in the queue...\n",
            "===========================> Rendering remaining 55 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 351/351 [00:19<00:00, 18.31it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 175 images in the queue...\n",
            "===========================> Rendering remaining 155 images in the queue...\n",
            "===========================> Rendering remaining 131 images in the queue...\n",
            "===========================> Rendering remaining 105 images in the queue...\n",
            "===========================> Rendering remaining 80 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 379/379 [00:16<00:00, 22.59it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 203 images in the queue...\n",
            "===========================> Rendering remaining 178 images in the queue...\n",
            "===========================> Rendering remaining 153 images in the queue...\n",
            "===========================> Rendering remaining 127 images in the queue...\n",
            "===========================> Rendering remaining 103 images in the queue...\n",
            "===========================> Rendering remaining 67 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 329/329 [00:13<00:00, 24.86it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 174 images in the queue...\n",
            "===========================> Rendering remaining 149 images in the queue...\n",
            "===========================> Rendering remaining 122 images in the queue...\n",
            "===========================> Rendering remaining 99 images in the queue...\n",
            "===========================> Rendering remaining 47 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 625/625 [00:35<00:00, 17.36it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 305 images in the queue...\n",
            "===========================> Rendering remaining 279 images in the queue...\n",
            "===========================> Rendering remaining 253 images in the queue...\n",
            "===========================> Rendering remaining 227 images in the queue...\n",
            "===========================> Rendering remaining 202 images in the queue...\n",
            "===========================> Rendering remaining 175 images in the queue...\n",
            "===========================> Rendering remaining 150 images in the queue...\n",
            "===========================> Rendering remaining 125 images in the queue...\n",
            "===========================> Rendering remaining 100 images in the queue...\n",
            "===========================> Rendering remaining 53 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 377/377 [00:16<00:00, 22.55it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 190 images in the queue...\n",
            "===========================> Rendering remaining 164 images in the queue...\n",
            "===========================> Rendering remaining 139 images in the queue...\n",
            "===========================> Rendering remaining 113 images in the queue...\n",
            "===========================> Rendering remaining 88 images in the queue...\n",
            "===========================> Rendering remaining 16 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 416/416 [00:15<00:00, 27.58it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 176 images in the queue...\n",
            "===========================> Rendering remaining 152 images in the queue...\n",
            "===========================> Rendering remaining 128 images in the queue...\n",
            "===========================> Rendering remaining 104 images in the queue...\n",
            "===========================> Rendering remaining 80 images in the queue...\n",
            "===========================> Rendering remaining 6 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 518/518 [00:25<00:00, 20.24it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 243 images in the queue...\n",
            "===========================> Rendering remaining 218 images in the queue...\n",
            "===========================> Rendering remaining 193 images in the queue...\n",
            "===========================> Rendering remaining 168 images in the queue...\n",
            "===========================> Rendering remaining 143 images in the queue...\n",
            "===========================> Rendering remaining 119 images in the queue...\n",
            "===========================> Rendering remaining 93 images in the queue...\n",
            "===========================> Rendering remaining 31 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 510/510 [00:25<00:00, 19.93it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 253 images in the queue...\n",
            "===========================> Rendering remaining 227 images in the queue...\n",
            "===========================> Rendering remaining 202 images in the queue...\n",
            "===========================> Rendering remaining 177 images in the queue...\n",
            "===========================> Rendering remaining 151 images in the queue...\n",
            "===========================> Rendering remaining 126 images in the queue...\n",
            "===========================> Rendering remaining 101 images in the queue...\n",
            "===========================> Rendering remaining 57 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 487/487 [00:20<00:00, 24.34it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 210 images in the queue...\n",
            "===========================> Rendering remaining 185 images in the queue...\n",
            "===========================> Rendering remaining 161 images in the queue...\n",
            "===========================> Rendering remaining 136 images in the queue...\n",
            "===========================> Rendering remaining 111 images in the queue...\n",
            "===========================> Rendering remaining 86 images in the queue...\n",
            "===========================> Rendering remaining 24 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 307/307 [00:11<00:00, 27.64it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 168 images in the queue...\n",
            "===========================> Rendering remaining 143 images in the queue...\n",
            "===========================> Rendering remaining 118 images in the queue...\n",
            "===========================> Rendering remaining 94 images in the queue...\n",
            "===========================> Rendering remaining 34 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 353/353 [00:14<00:00, 24.09it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 192 images in the queue...\n",
            "===========================> Rendering remaining 167 images in the queue...\n",
            "===========================> Rendering remaining 142 images in the queue...\n",
            "===========================> Rendering remaining 117 images in the queue...\n",
            "===========================> Rendering remaining 93 images in the queue...\n",
            "===========================> Rendering remaining 36 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 516/516 [00:26<00:00, 19.30it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 275 images in the queue...\n",
            "===========================> Rendering remaining 254 images in the queue...\n",
            "===========================> Rendering remaining 230 images in the queue...\n",
            "===========================> Rendering remaining 207 images in the queue...\n",
            "===========================> Rendering remaining 186 images in the queue...\n",
            "===========================> Rendering remaining 163 images in the queue...\n",
            "===========================> Rendering remaining 140 images in the queue...\n",
            "===========================> Rendering remaining 119 images in the queue...\n",
            "===========================> Rendering remaining 97 images in the queue...\n",
            "===========================> Rendering remaining 51 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 376/376 [00:16<00:00, 22.62it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 201 images in the queue...\n",
            "===========================> Rendering remaining 177 images in the queue...\n",
            "===========================> Rendering remaining 151 images in the queue...\n",
            "===========================> Rendering remaining 126 images in the queue...\n",
            "===========================> Rendering remaining 100 images in the queue...\n",
            "===========================> Rendering remaining 52 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 327/327 [00:14<00:00, 23.09it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 174 images in the queue...\n",
            "===========================> Rendering remaining 150 images in the queue...\n",
            "===========================> Rendering remaining 126 images in the queue...\n",
            "===========================> Rendering remaining 102 images in the queue...\n",
            "===========================> Rendering remaining 63 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 366/366 [00:16<00:00, 21.86it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 149 images in the queue...\n",
            "===========================> Rendering remaining 124 images in the queue...\n",
            "===========================> Rendering remaining 99 images in the queue...\n",
            "===========================> Rendering remaining 49 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 462/462 [00:22<00:00, 20.83it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 239 images in the queue...\n",
            "===========================> Rendering remaining 215 images in the queue...\n",
            "===========================> Rendering remaining 190 images in the queue...\n",
            "===========================> Rendering remaining 165 images in the queue...\n",
            "===========================> Rendering remaining 141 images in the queue...\n",
            "===========================> Rendering remaining 116 images in the queue...\n",
            "===========================> Rendering remaining 92 images in the queue...\n",
            "===========================> Rendering remaining 44 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 419/419 [00:19<00:00, 21.63it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 217 images in the queue...\n",
            "===========================> Rendering remaining 193 images in the queue...\n",
            "===========================> Rendering remaining 168 images in the queue...\n",
            "===========================> Rendering remaining 144 images in the queue...\n",
            "===========================> Rendering remaining 119 images in the queue...\n",
            "===========================> Rendering remaining 95 images in the queue...\n",
            "===========================> Rendering remaining 40 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 296/296 [00:11<00:00, 25.89it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 164 images in the queue...\n",
            "===========================> Rendering remaining 142 images in the queue...\n",
            "===========================> Rendering remaining 118 images in the queue...\n",
            "===========================> Rendering remaining 96 images in the queue...\n",
            "===========================> Rendering remaining 47 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 312/312 [00:11<00:00, 26.26it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 189 images in the queue...\n",
            "===========================> Rendering remaining 165 images in the queue...\n",
            "===========================> Rendering remaining 141 images in the queue...\n",
            "===========================> Rendering remaining 117 images in the queue...\n",
            "===========================> Rendering remaining 93 images in the queue...\n",
            "===========================> Rendering remaining 35 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 226/226 [00:07<00:00, 30.41it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 134 images in the queue...\n",
            "===========================> Rendering remaining 110 images in the queue...\n",
            "===========================> Rendering remaining 85 images in the queue...\n",
            "===========================> Rendering remaining 8 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 739/739 [00:28<00:00, 25.78it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 399 images in the queue...\n",
            "===========================> Rendering remaining 375 images in the queue...\n",
            "===========================> Rendering remaining 351 images in the queue...\n",
            "===========================> Rendering remaining 308 images in the queue...\n",
            "===========================> Rendering remaining 228 images in the queue...\n",
            "===========================> Rendering remaining 150 images in the queue...\n",
            "===========================> Rendering remaining 72 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "  0% 0/1078 [00:00<?, ?it/s]Try to use other video encoders...\n",
            "100% 1078/1078 [00:53<00:00, 20.13it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 579 images in the queue...\n",
            "===========================> Rendering remaining 555 images in the queue...\n",
            "===========================> Rendering remaining 531 images in the queue...\n",
            "===========================> Rendering remaining 507 images in the queue...\n",
            "===========================> Rendering remaining 481 images in the queue...\n",
            "===========================> Rendering remaining 456 images in the queue...\n",
            "===========================> Rendering remaining 432 images in the queue...\n",
            "===========================> Rendering remaining 376 images in the queue...\n",
            "===========================> Rendering remaining 296 images in the queue...\n",
            "===========================> Rendering remaining 218 images in the queue...\n",
            "===========================> Rendering remaining 139 images in the queue...\n",
            "===========================> Rendering remaining 63 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 891/891 [00:40<00:00, 21.91it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 459 images in the queue...\n",
            "===========================> Rendering remaining 435 images in the queue...\n",
            "===========================> Rendering remaining 409 images in the queue...\n",
            "===========================> Rendering remaining 384 images in the queue...\n",
            "===========================> Rendering remaining 358 images in the queue...\n",
            "===========================> Rendering remaining 319 images in the queue...\n",
            "===========================> Rendering remaining 237 images in the queue...\n",
            "===========================> Rendering remaining 158 images in the queue...\n",
            "===========================> Rendering remaining 79 images in the queue...\n",
            "===========================> Rendering remaining 2 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 647/647 [00:24<00:00, 26.35it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 342 images in the queue...\n",
            "===========================> Rendering remaining 319 images in the queue...\n",
            "===========================> Rendering remaining 295 images in the queue...\n",
            "===========================> Rendering remaining 264 images in the queue...\n",
            "===========================> Rendering remaining 188 images in the queue...\n",
            "===========================> Rendering remaining 110 images in the queue...\n",
            "===========================> Rendering remaining 33 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 895/895 [00:41<00:00, 21.33it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 462 images in the queue...\n",
            "===========================> Rendering remaining 437 images in the queue...\n",
            "===========================> Rendering remaining 412 images in the queue...\n",
            "===========================> Rendering remaining 387 images in the queue...\n",
            "===========================> Rendering remaining 361 images in the queue...\n",
            "===========================> Rendering remaining 283 images in the queue...\n",
            "===========================> Rendering remaining 202 images in the queue...\n",
            "===========================> Rendering remaining 122 images in the queue...\n",
            "===========================> Rendering remaining 44 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 668/668 [00:26<00:00, 25.34it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 338 images in the queue...\n",
            "===========================> Rendering remaining 312 images in the queue...\n",
            "===========================> Rendering remaining 284 images in the queue...\n",
            "===========================> Rendering remaining 203 images in the queue...\n",
            "===========================> Rendering remaining 123 images in the queue...\n",
            "===========================> Rendering remaining 43 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 738/738 [00:28<00:00, 25.87it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 406 images in the queue...\n",
            "===========================> Rendering remaining 349 images in the queue...\n",
            "===========================> Rendering remaining 267 images in the queue...\n",
            "===========================> Rendering remaining 187 images in the queue...\n",
            "===========================> Rendering remaining 105 images in the queue...\n",
            "===========================> Rendering remaining 27 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 704/704 [00:30<00:00, 23.40it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 338 images in the queue...\n",
            "===========================> Rendering remaining 312 images in the queue...\n",
            "===========================> Rendering remaining 286 images in the queue...\n",
            "===========================> Rendering remaining 232 images in the queue...\n",
            "===========================> Rendering remaining 153 images in the queue...\n",
            "===========================> Rendering remaining 73 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 996/996 [00:46<00:00, 21.31it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 527 images in the queue...\n",
            "===========================> Rendering remaining 501 images in the queue...\n",
            "===========================> Rendering remaining 475 images in the queue...\n",
            "===========================> Rendering remaining 448 images in the queue...\n",
            "===========================> Rendering remaining 367 images in the queue...\n",
            "===========================> Rendering remaining 285 images in the queue...\n",
            "===========================> Rendering remaining 206 images in the queue...\n",
            "===========================> Rendering remaining 126 images in the queue...\n",
            "===========================> Rendering remaining 45 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 730/730 [00:28<00:00, 25.34it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 380 images in the queue...\n",
            "===========================> Rendering remaining 354 images in the queue...\n",
            "===========================> Rendering remaining 316 images in the queue...\n",
            "===========================> Rendering remaining 233 images in the queue...\n",
            "===========================> Rendering remaining 152 images in the queue...\n",
            "===========================> Rendering remaining 72 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 629/629 [00:17<00:00, 35.73it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 282 images in the queue...\n",
            "===========================> Rendering remaining 203 images in the queue...\n",
            "===========================> Rendering remaining 124 images in the queue...\n",
            "===========================> Rendering remaining 43 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 862/862 [00:40<00:00, 21.04it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 434 images in the queue...\n",
            "===========================> Rendering remaining 408 images in the queue...\n",
            "===========================> Rendering remaining 383 images in the queue...\n",
            "===========================> Rendering remaining 358 images in the queue...\n",
            "===========================> Rendering remaining 314 images in the queue...\n",
            "===========================> Rendering remaining 231 images in the queue...\n",
            "===========================> Rendering remaining 150 images in the queue...\n",
            "===========================> Rendering remaining 68 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 623/623 [00:26<00:00, 23.24it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 291 images in the queue...\n",
            "===========================> Rendering remaining 267 images in the queue...\n",
            "===========================> Rendering remaining 242 images in the queue...\n",
            "===========================> Rendering remaining 217 images in the queue...\n",
            "===========================> Rendering remaining 181 images in the queue...\n",
            "===========================> Rendering remaining 98 images in the queue...\n",
            "===========================> Rendering remaining 21 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 896/896 [00:43<00:00, 20.50it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 460 images in the queue...\n",
            "===========================> Rendering remaining 435 images in the queue...\n",
            "===========================> Rendering remaining 411 images in the queue...\n",
            "===========================> Rendering remaining 386 images in the queue...\n",
            "===========================> Rendering remaining 361 images in the queue...\n",
            "===========================> Rendering remaining 306 images in the queue...\n",
            "===========================> Rendering remaining 223 images in the queue...\n",
            "===========================> Rendering remaining 140 images in the queue...\n",
            "===========================> Rendering remaining 59 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 690/690 [00:26<00:00, 25.76it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 351 images in the queue...\n",
            "===========================> Rendering remaining 325 images in the queue...\n",
            "===========================> Rendering remaining 248 images in the queue...\n",
            "===========================> Rendering remaining 167 images in the queue...\n",
            "===========================> Rendering remaining 85 images in the queue...\n",
            "===========================> Rendering remaining 7 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 661/661 [00:26<00:00, 24.91it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 333 images in the queue...\n",
            "===========================> Rendering remaining 308 images in the queue...\n",
            "===========================> Rendering remaining 282 images in the queue...\n",
            "===========================> Rendering remaining 219 images in the queue...\n",
            "===========================> Rendering remaining 137 images in the queue...\n",
            "===========================> Rendering remaining 57 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 736/736 [00:35<00:00, 20.52it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 449 images in the queue...\n",
            "===========================> Rendering remaining 432 images in the queue...\n",
            "===========================> Rendering remaining 415 images in the queue...\n",
            "===========================> Rendering remaining 397 images in the queue...\n",
            "===========================> Rendering remaining 381 images in the queue...\n",
            "===========================> Rendering remaining 364 images in the queue...\n",
            "===========================> Rendering remaining 348 images in the queue...\n",
            "===========================> Rendering remaining 331 images in the queue...\n",
            "===========================> Rendering remaining 314 images in the queue...\n",
            "===========================> Rendering remaining 276 images in the queue...\n",
            "===========================> Rendering remaining 194 images in the queue...\n",
            "===========================> Rendering remaining 115 images in the queue...\n",
            "===========================> Rendering remaining 35 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 655/655 [00:28<00:00, 23.32it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 293 images in the queue...\n",
            "===========================> Rendering remaining 267 images in the queue...\n",
            "===========================> Rendering remaining 241 images in the queue...\n",
            "===========================> Rendering remaining 214 images in the queue...\n",
            "===========================> Rendering remaining 188 images in the queue...\n",
            "===========================> Rendering remaining 117 images in the queue...\n",
            "===========================> Rendering remaining 36 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 770/770 [00:32<00:00, 23.96it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 403 images in the queue...\n",
            "===========================> Rendering remaining 377 images in the queue...\n",
            "===========================> Rendering remaining 351 images in the queue...\n",
            "===========================> Rendering remaining 306 images in the queue...\n",
            "===========================> Rendering remaining 223 images in the queue...\n",
            "===========================> Rendering remaining 141 images in the queue...\n",
            "===========================> Rendering remaining 59 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 777/777 [00:33<00:00, 23.20it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 400 images in the queue...\n",
            "===========================> Rendering remaining 374 images in the queue...\n",
            "===========================> Rendering remaining 348 images in the queue...\n",
            "===========================> Rendering remaining 297 images in the queue...\n",
            "===========================> Rendering remaining 214 images in the queue...\n",
            "===========================> Rendering remaining 133 images in the queue...\n",
            "===========================> Rendering remaining 55 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 720/720 [00:27<00:00, 25.96it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 386 images in the queue...\n",
            "===========================> Rendering remaining 362 images in the queue...\n",
            "===========================> Rendering remaining 337 images in the queue...\n",
            "===========================> Rendering remaining 262 images in the queue...\n",
            "===========================> Rendering remaining 181 images in the queue...\n",
            "===========================> Rendering remaining 99 images in the queue...\n",
            "===========================> Rendering remaining 19 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 795/795 [00:33<00:00, 23.69it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 384 images in the queue...\n",
            "===========================> Rendering remaining 350 images in the queue...\n",
            "===========================> Rendering remaining 311 images in the queue...\n",
            "===========================> Rendering remaining 229 images in the queue...\n",
            "===========================> Rendering remaining 148 images in the queue...\n",
            "===========================> Rendering remaining 67 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 897/897 [00:44<00:00, 20.28it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 426 images in the queue...\n",
            "===========================> Rendering remaining 401 images in the queue...\n",
            "===========================> Rendering remaining 374 images in the queue...\n",
            "===========================> Rendering remaining 346 images in the queue...\n",
            "===========================> Rendering remaining 320 images in the queue...\n",
            "===========================> Rendering remaining 275 images in the queue...\n",
            "===========================> Rendering remaining 203 images in the queue...\n",
            "===========================> Rendering remaining 125 images in the queue...\n",
            "===========================> Rendering remaining 49 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 719/719 [00:35<00:00, 20.47it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 334 images in the queue...\n",
            "===========================> Rendering remaining 308 images in the queue...\n",
            "===========================> Rendering remaining 269 images in the queue...\n",
            "===========================> Rendering remaining 189 images in the queue...\n",
            "===========================> Rendering remaining 107 images in the queue...\n",
            "===========================> Rendering remaining 25 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 862/862 [00:40<00:00, 21.36it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 432 images in the queue...\n",
            "===========================> Rendering remaining 405 images in the queue...\n",
            "===========================> Rendering remaining 380 images in the queue...\n",
            "===========================> Rendering remaining 345 images in the queue...\n",
            "===========================> Rendering remaining 263 images in the queue...\n",
            "===========================> Rendering remaining 182 images in the queue...\n",
            "===========================> Rendering remaining 104 images in the queue...\n",
            "===========================> Rendering remaining 25 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 802/802 [00:32<00:00, 24.65it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 431 images in the queue...\n",
            "===========================> Rendering remaining 403 images in the queue...\n",
            "===========================> Rendering remaining 322 images in the queue...\n",
            "===========================> Rendering remaining 241 images in the queue...\n",
            "===========================> Rendering remaining 159 images in the queue...\n",
            "===========================> Rendering remaining 78 images in the queue...\n",
            "===========================> Rendering remaining 3 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 751/751 [00:31<00:00, 24.21it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 388 images in the queue...\n",
            "===========================> Rendering remaining 362 images in the queue...\n",
            "===========================> Rendering remaining 338 images in the queue...\n",
            "===========================> Rendering remaining 267 images in the queue...\n",
            "===========================> Rendering remaining 184 images in the queue...\n",
            "===========================> Rendering remaining 104 images in the queue...\n",
            "===========================> Rendering remaining 24 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 779/779 [00:35<00:00, 22.02it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 372 images in the queue...\n",
            "===========================> Rendering remaining 346 images in the queue...\n",
            "===========================> Rendering remaining 320 images in the queue...\n",
            "===========================> Rendering remaining 295 images in the queue...\n",
            "===========================> Rendering remaining 266 images in the queue...\n",
            "===========================> Rendering remaining 187 images in the queue...\n",
            "===========================> Rendering remaining 107 images in the queue...\n",
            "===========================> Rendering remaining 32 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 712/712 [00:25<00:00, 27.69it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 400 images in the queue...\n",
            "===========================> Rendering remaining 333 images in the queue...\n",
            "===========================> Rendering remaining 252 images in the queue...\n",
            "===========================> Rendering remaining 172 images in the queue...\n",
            "===========================> Rendering remaining 92 images in the queue...\n",
            "===========================> Rendering remaining 16 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 1023/1023 [00:56<00:00, 17.98it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 472 images in the queue...\n",
            "===========================> Rendering remaining 447 images in the queue...\n",
            "===========================> Rendering remaining 421 images in the queue...\n",
            "===========================> Rendering remaining 393 images in the queue...\n",
            "===========================> Rendering remaining 366 images in the queue...\n",
            "===========================> Rendering remaining 341 images in the queue...\n",
            "===========================> Rendering remaining 316 images in the queue...\n",
            "===========================> Rendering remaining 296 images in the queue...\n",
            "===========================> Rendering remaining 233 images in the queue...\n",
            "===========================> Rendering remaining 157 images in the queue...\n",
            "===========================> Rendering remaining 77 images in the queue...\n",
            "===========================> Rendering remaining 4 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 661/661 [00:26<00:00, 24.67it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 325 images in the queue...\n",
            "===========================> Rendering remaining 299 images in the queue...\n",
            "===========================> Rendering remaining 276 images in the queue...\n",
            "===========================> Rendering remaining 203 images in the queue...\n",
            "===========================> Rendering remaining 123 images in the queue...\n",
            "===========================> Rendering remaining 43 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 828/828 [00:36<00:00, 22.84it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 440 images in the queue...\n",
            "===========================> Rendering remaining 414 images in the queue...\n",
            "===========================> Rendering remaining 390 images in the queue...\n",
            "===========================> Rendering remaining 365 images in the queue...\n",
            "===========================> Rendering remaining 336 images in the queue...\n",
            "===========================> Rendering remaining 256 images in the queue...\n",
            "===========================> Rendering remaining 178 images in the queue...\n",
            "===========================> Rendering remaining 102 images in the queue...\n",
            "===========================> Rendering remaining 25 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 597/597 [00:15<00:00, 37.78it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 364 images in the queue...\n",
            "===========================> Rendering remaining 287 images in the queue...\n",
            "===========================> Rendering remaining 208 images in the queue...\n",
            "===========================> Rendering remaining 130 images in the queue...\n",
            "===========================> Rendering remaining 56 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 949/949 [00:45<00:00, 20.74it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 486 images in the queue...\n",
            "===========================> Rendering remaining 460 images in the queue...\n",
            "===========================> Rendering remaining 434 images in the queue...\n",
            "===========================> Rendering remaining 409 images in the queue...\n",
            "===========================> Rendering remaining 383 images in the queue...\n",
            "===========================> Rendering remaining 357 images in the queue...\n",
            "===========================> Rendering remaining 294 images in the queue...\n",
            "===========================> Rendering remaining 213 images in the queue...\n",
            "===========================> Rendering remaining 135 images in the queue...\n",
            "===========================> Rendering remaining 58 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 961/961 [00:47<00:00, 20.04it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 529 images in the queue...\n",
            "===========================> Rendering remaining 505 images in the queue...\n",
            "===========================> Rendering remaining 480 images in the queue...\n",
            "===========================> Rendering remaining 455 images in the queue...\n",
            "===========================> Rendering remaining 432 images in the queue...\n",
            "===========================> Rendering remaining 409 images in the queue...\n",
            "===========================> Rendering remaining 386 images in the queue...\n",
            "===========================> Rendering remaining 366 images in the queue...\n",
            "===========================> Rendering remaining 294 images in the queue...\n",
            "===========================> Rendering remaining 215 images in the queue...\n",
            "===========================> Rendering remaining 137 images in the queue...\n",
            "===========================> Rendering remaining 58 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 947/947 [00:42<00:00, 22.24it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 531 images in the queue...\n",
            "===========================> Rendering remaining 506 images in the queue...\n",
            "===========================> Rendering remaining 481 images in the queue...\n",
            "===========================> Rendering remaining 456 images in the queue...\n",
            "===========================> Rendering remaining 420 images in the queue...\n",
            "===========================> Rendering remaining 340 images in the queue...\n",
            "===========================> Rendering remaining 259 images in the queue...\n",
            "===========================> Rendering remaining 178 images in the queue...\n",
            "===========================> Rendering remaining 99 images in the queue...\n",
            "===========================> Rendering remaining 23 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 830/830 [00:28<00:00, 29.46it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 469 images in the queue...\n",
            "===========================> Rendering remaining 390 images in the queue...\n",
            "===========================> Rendering remaining 313 images in the queue...\n",
            "===========================> Rendering remaining 233 images in the queue...\n",
            "===========================> Rendering remaining 153 images in the queue...\n",
            "===========================> Rendering remaining 76 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 812/812 [00:32<00:00, 25.06it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 455 images in the queue...\n",
            "===========================> Rendering remaining 429 images in the queue...\n",
            "===========================> Rendering remaining 398 images in the queue...\n",
            "===========================> Rendering remaining 317 images in the queue...\n",
            "===========================> Rendering remaining 234 images in the queue...\n",
            "===========================> Rendering remaining 154 images in the queue...\n",
            "===========================> Rendering remaining 75 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 807/807 [00:37<00:00, 21.45it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 394 images in the queue...\n",
            "===========================> Rendering remaining 368 images in the queue...\n",
            "===========================> Rendering remaining 344 images in the queue...\n",
            "===========================> Rendering remaining 318 images in the queue...\n",
            "===========================> Rendering remaining 292 images in the queue...\n",
            "===========================> Rendering remaining 254 images in the queue...\n",
            "===========================> Rendering remaining 175 images in the queue...\n",
            "===========================> Rendering remaining 98 images in the queue...\n",
            "===========================> Rendering remaining 23 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 842/842 [00:34<00:00, 24.10it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 457 images in the queue...\n",
            "===========================> Rendering remaining 433 images in the queue...\n",
            "===========================> Rendering remaining 408 images in the queue...\n",
            "===========================> Rendering remaining 382 images in the queue...\n",
            "===========================> Rendering remaining 348 images in the queue...\n",
            "===========================> Rendering remaining 266 images in the queue...\n",
            "===========================> Rendering remaining 185 images in the queue...\n",
            "===========================> Rendering remaining 105 images in the queue...\n",
            "===========================> Rendering remaining 27 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 959/959 [00:52<00:00, 18.42it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 467 images in the queue...\n",
            "===========================> Rendering remaining 444 images in the queue...\n",
            "===========================> Rendering remaining 419 images in the queue...\n",
            "===========================> Rendering remaining 395 images in the queue...\n",
            "===========================> Rendering remaining 369 images in the queue...\n",
            "===========================> Rendering remaining 347 images in the queue...\n",
            "===========================> Rendering remaining 273 images in the queue...\n",
            "===========================> Rendering remaining 194 images in the queue...\n",
            "===========================> Rendering remaining 116 images in the queue...\n",
            "===========================> Rendering remaining 36 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 865/865 [00:41<00:00, 21.02it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 437 images in the queue...\n",
            "===========================> Rendering remaining 412 images in the queue...\n",
            "===========================> Rendering remaining 387 images in the queue...\n",
            "===========================> Rendering remaining 362 images in the queue...\n",
            "===========================> Rendering remaining 336 images in the queue...\n",
            "===========================> Rendering remaining 312 images in the queue...\n",
            "===========================> Rendering remaining 284 images in the queue...\n",
            "===========================> Rendering remaining 204 images in the queue...\n",
            "===========================> Rendering remaining 125 images in the queue...\n",
            "===========================> Rendering remaining 45 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "  0% 0/784 [00:00<?, ?it/s]Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 784/784 [00:41<00:00, 18.77it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 390 images in the queue...\n",
            "===========================> Rendering remaining 366 images in the queue...\n",
            "===========================> Rendering remaining 342 images in the queue...\n",
            "===========================> Rendering remaining 320 images in the queue...\n",
            "===========================> Rendering remaining 296 images in the queue...\n",
            "===========================> Rendering remaining 233 images in the queue...\n",
            "===========================> Rendering remaining 152 images in the queue...\n",
            "===========================> Rendering remaining 72 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 1002/1002 [00:46<00:00, 21.63it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 551 images in the queue...\n",
            "===========================> Rendering remaining 526 images in the queue...\n",
            "===========================> Rendering remaining 502 images in the queue...\n",
            "===========================> Rendering remaining 477 images in the queue...\n",
            "===========================> Rendering remaining 452 images in the queue...\n",
            "===========================> Rendering remaining 402 images in the queue...\n",
            "===========================> Rendering remaining 323 images in the queue...\n",
            "===========================> Rendering remaining 244 images in the queue...\n",
            "===========================> Rendering remaining 164 images in the queue...\n",
            "===========================> Rendering remaining 85 images in the queue...\n",
            "===========================> Rendering remaining 8 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 851/851 [00:38<00:00, 22.34it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 464 images in the queue...\n",
            "===========================> Rendering remaining 439 images in the queue...\n",
            "===========================> Rendering remaining 360 images in the queue...\n",
            "===========================> Rendering remaining 282 images in the queue...\n",
            "===========================> Rendering remaining 201 images in the queue...\n",
            "===========================> Rendering remaining 122 images in the queue...\n",
            "===========================> Rendering remaining 43 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "  0% 0/753 [00:00<?, ?it/s]Try to use other video encoders...\n",
            "100% 753/753 [00:31<00:00, 24.16it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 400 images in the queue...\n",
            "===========================> Rendering remaining 319 images in the queue...\n",
            "===========================> Rendering remaining 239 images in the queue...\n",
            "===========================> Rendering remaining 161 images in the queue...\n",
            "===========================> Rendering remaining 80 images in the queue...\n",
            "===========================> Rendering remaining 4 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 870/870 [00:36<00:00, 23.64it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 452 images in the queue...\n",
            "===========================> Rendering remaining 427 images in the queue...\n",
            "===========================> Rendering remaining 399 images in the queue...\n",
            "===========================> Rendering remaining 319 images in the queue...\n",
            "===========================> Rendering remaining 241 images in the queue...\n",
            "===========================> Rendering remaining 163 images in the queue...\n",
            "===========================> Rendering remaining 84 images in the queue...\n",
            "===========================> Rendering remaining 9 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 799/799 [00:34<00:00, 23.29it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 472 images in the queue...\n",
            "===========================> Rendering remaining 450 images in the queue...\n",
            "===========================> Rendering remaining 432 images in the queue...\n",
            "===========================> Rendering remaining 414 images in the queue...\n",
            "===========================> Rendering remaining 396 images in the queue...\n",
            "===========================> Rendering remaining 324 images in the queue...\n",
            "===========================> Rendering remaining 244 images in the queue...\n",
            "===========================> Rendering remaining 166 images in the queue...\n",
            "===========================> Rendering remaining 90 images in the queue...\n",
            "===========================> Rendering remaining 14 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 615/615 [00:17<00:00, 35.97it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 365 images in the queue...\n",
            "===========================> Rendering remaining 295 images in the queue...\n",
            "===========================> Rendering remaining 216 images in the queue...\n",
            "===========================> Rendering remaining 136 images in the queue...\n",
            "===========================> Rendering remaining 57 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 813/813 [00:35<00:00, 22.76it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 552 images in the queue...\n",
            "===========================> Rendering remaining 536 images in the queue...\n",
            "===========================> Rendering remaining 522 images in the queue...\n",
            "===========================> Rendering remaining 508 images in the queue...\n",
            "===========================> Rendering remaining 494 images in the queue...\n",
            "===========================> Rendering remaining 478 images in the queue...\n",
            "===========================> Rendering remaining 460 images in the queue...\n",
            "===========================> Rendering remaining 444 images in the queue...\n",
            "===========================> Rendering remaining 429 images in the queue...\n",
            "===========================> Rendering remaining 384 images in the queue...\n",
            "===========================> Rendering remaining 303 images in the queue...\n",
            "===========================> Rendering remaining 222 images in the queue...\n",
            "===========================> Rendering remaining 142 images in the queue...\n",
            "===========================> Rendering remaining 62 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 728/728 [00:26<00:00, 27.70it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 399 images in the queue...\n",
            "===========================> Rendering remaining 374 images in the queue...\n",
            "===========================> Rendering remaining 316 images in the queue...\n",
            "===========================> Rendering remaining 236 images in the queue...\n",
            "===========================> Rendering remaining 155 images in the queue...\n",
            "===========================> Rendering remaining 74 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 1143/1143 [00:58<00:00, 19.61it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 596 images in the queue...\n",
            "===========================> Rendering remaining 570 images in the queue...\n",
            "===========================> Rendering remaining 545 images in the queue...\n",
            "===========================> Rendering remaining 520 images in the queue...\n",
            "===========================> Rendering remaining 494 images in the queue...\n",
            "===========================> Rendering remaining 468 images in the queue...\n",
            "===========================> Rendering remaining 443 images in the queue...\n",
            "===========================> Rendering remaining 367 images in the queue...\n",
            "===========================> Rendering remaining 286 images in the queue...\n",
            "===========================> Rendering remaining 206 images in the queue...\n",
            "===========================> Rendering remaining 126 images in the queue...\n",
            "===========================> Rendering remaining 47 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 882/882 [00:40<00:00, 21.81it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 466 images in the queue...\n",
            "===========================> Rendering remaining 440 images in the queue...\n",
            "===========================> Rendering remaining 415 images in the queue...\n",
            "===========================> Rendering remaining 389 images in the queue...\n",
            "===========================> Rendering remaining 365 images in the queue...\n",
            "===========================> Rendering remaining 285 images in the queue...\n",
            "===========================> Rendering remaining 207 images in the queue...\n",
            "===========================> Rendering remaining 128 images in the queue...\n",
            "===========================> Rendering remaining 52 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 1011/1011 [00:47<00:00, 21.35it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 554 images in the queue...\n",
            "===========================> Rendering remaining 528 images in the queue...\n",
            "===========================> Rendering remaining 503 images in the queue...\n",
            "===========================> Rendering remaining 479 images in the queue...\n",
            "===========================> Rendering remaining 453 images in the queue...\n",
            "===========================> Rendering remaining 428 images in the queue...\n",
            "===========================> Rendering remaining 355 images in the queue...\n",
            "===========================> Rendering remaining 274 images in the queue...\n",
            "===========================> Rendering remaining 192 images in the queue...\n",
            "===========================> Rendering remaining 112 images in the queue...\n",
            "===========================> Rendering remaining 34 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 806/806 [00:33<00:00, 23.73it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 432 images in the queue...\n",
            "===========================> Rendering remaining 407 images in the queue...\n",
            "===========================> Rendering remaining 382 images in the queue...\n",
            "===========================> Rendering remaining 357 images in the queue...\n",
            "===========================> Rendering remaining 293 images in the queue...\n",
            "===========================> Rendering remaining 214 images in the queue...\n",
            "===========================> Rendering remaining 133 images in the queue...\n",
            "===========================> Rendering remaining 55 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 608/608 [00:17<00:00, 34.26it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 349 images in the queue...\n",
            "===========================> Rendering remaining 316 images in the queue...\n",
            "===========================> Rendering remaining 237 images in the queue...\n",
            "===========================> Rendering remaining 158 images in the queue...\n",
            "===========================> Rendering remaining 78 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 638/638 [00:23<00:00, 27.61it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 350 images in the queue...\n",
            "===========================> Rendering remaining 325 images in the queue...\n",
            "===========================> Rendering remaining 301 images in the queue...\n",
            "===========================> Rendering remaining 276 images in the queue...\n",
            "===========================> Rendering remaining 197 images in the queue...\n",
            "===========================> Rendering remaining 119 images in the queue...\n",
            "===========================> Rendering remaining 38 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 776/776 [00:23<00:00, 32.42it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 351 images in the queue...\n",
            "===========================> Rendering remaining 271 images in the queue...\n",
            "===========================> Rendering remaining 190 images in the queue...\n",
            "===========================> Rendering remaining 113 images in the queue...\n",
            "===========================> Rendering remaining 40 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 692/692 [00:24<00:00, 28.72it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 383 images in the queue...\n",
            "===========================> Rendering remaining 357 images in the queue...\n",
            "===========================> Rendering remaining 329 images in the queue...\n",
            "===========================> Rendering remaining 249 images in the queue...\n",
            "===========================> Rendering remaining 169 images in the queue...\n",
            "===========================> Rendering remaining 90 images in the queue...\n",
            "===========================> Rendering remaining 13 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 723/723 [00:27<00:00, 26.23it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 395 images in the queue...\n",
            "===========================> Rendering remaining 369 images in the queue...\n",
            "===========================> Rendering remaining 344 images in the queue...\n",
            "===========================> Rendering remaining 284 images in the queue...\n",
            "===========================> Rendering remaining 203 images in the queue...\n",
            "===========================> Rendering remaining 121 images in the queue...\n",
            "===========================> Rendering remaining 43 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 832/832 [00:33<00:00, 24.80it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 460 images in the queue...\n",
            "===========================> Rendering remaining 434 images in the queue...\n",
            "===========================> Rendering remaining 409 images in the queue...\n",
            "===========================> Rendering remaining 329 images in the queue...\n",
            "===========================> Rendering remaining 248 images in the queue...\n",
            "===========================> Rendering remaining 168 images in the queue...\n",
            "===========================> Rendering remaining 87 images in the queue...\n",
            "===========================> Rendering remaining 12 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 896/896 [00:34<00:00, 25.77it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 519 images in the queue...\n",
            "===========================> Rendering remaining 492 images in the queue...\n",
            "===========================> Rendering remaining 411 images in the queue...\n",
            "===========================> Rendering remaining 330 images in the queue...\n",
            "===========================> Rendering remaining 251 images in the queue...\n",
            "===========================> Rendering remaining 172 images in the queue...\n",
            "===========================> Rendering remaining 93 images in the queue...\n",
            "===========================> Rendering remaining 16 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 849/849 [00:41<00:00, 20.53it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 393 images in the queue...\n",
            "===========================> Rendering remaining 366 images in the queue...\n",
            "===========================> Rendering remaining 340 images in the queue...\n",
            "===========================> Rendering remaining 314 images in the queue...\n",
            "===========================> Rendering remaining 287 images in the queue...\n",
            "===========================> Rendering remaining 261 images in the queue...\n",
            "===========================> Rendering remaining 187 images in the queue...\n",
            "===========================> Rendering remaining 109 images in the queue...\n",
            "===========================> Rendering remaining 30 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 1037/1037 [00:50<00:00, 20.71it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 535 images in the queue...\n",
            "===========================> Rendering remaining 509 images in the queue...\n",
            "===========================> Rendering remaining 484 images in the queue...\n",
            "===========================> Rendering remaining 458 images in the queue...\n",
            "===========================> Rendering remaining 432 images in the queue...\n",
            "===========================> Rendering remaining 377 images in the queue...\n",
            "===========================> Rendering remaining 295 images in the queue...\n",
            "===========================> Rendering remaining 215 images in the queue...\n",
            "===========================> Rendering remaining 136 images in the queue...\n",
            "===========================> Rendering remaining 57 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "  0% 0/918 [00:00<?, ?it/s]Try to use other video encoders...\n",
            "100% 918/918 [00:39<00:00, 23.04it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 550 images in the queue...\n",
            "===========================> Rendering remaining 529 images in the queue...\n",
            "===========================> Rendering remaining 508 images in the queue...\n",
            "===========================> Rendering remaining 483 images in the queue...\n",
            "===========================> Rendering remaining 463 images in the queue...\n",
            "===========================> Rendering remaining 444 images in the queue...\n",
            "===========================> Rendering remaining 374 images in the queue...\n",
            "===========================> Rendering remaining 293 images in the queue...\n",
            "===========================> Rendering remaining 214 images in the queue...\n",
            "===========================> Rendering remaining 136 images in the queue...\n",
            "===========================> Rendering remaining 60 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 667/667 [00:30<00:00, 22.20it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 295 images in the queue...\n",
            "===========================> Rendering remaining 269 images in the queue...\n",
            "===========================> Rendering remaining 212 images in the queue...\n",
            "===========================> Rendering remaining 132 images in the queue...\n",
            "===========================> Rendering remaining 52 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 748/748 [00:25<00:00, 29.63it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 441 images in the queue...\n",
            "===========================> Rendering remaining 404 images in the queue...\n",
            "===========================> Rendering remaining 325 images in the queue...\n",
            "===========================> Rendering remaining 243 images in the queue...\n",
            "===========================> Rendering remaining 162 images in the queue...\n",
            "===========================> Rendering remaining 82 images in the queue...\n",
            "===========================> Rendering remaining 3 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "  0% 0/675 [00:00<?, ?it/s]Try to use other video encoders...\n",
            "100% 675/675 [00:19<00:00, 34.21it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 413 images in the queue...\n",
            "===========================> Rendering remaining 360 images in the queue...\n",
            "===========================> Rendering remaining 281 images in the queue...\n",
            "===========================> Rendering remaining 200 images in the queue...\n",
            "===========================> Rendering remaining 120 images in the queue...\n",
            "===========================> Rendering remaining 40 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 833/833 [00:36<00:00, 23.13it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 500 images in the queue...\n",
            "===========================> Rendering remaining 478 images in the queue...\n",
            "===========================> Rendering remaining 456 images in the queue...\n",
            "===========================> Rendering remaining 434 images in the queue...\n",
            "===========================> Rendering remaining 411 images in the queue...\n",
            "===========================> Rendering remaining 376 images in the queue...\n",
            "===========================> Rendering remaining 294 images in the queue...\n",
            "===========================> Rendering remaining 213 images in the queue...\n",
            "===========================> Rendering remaining 131 images in the queue...\n",
            "===========================> Rendering remaining 53 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 840/840 [00:37<00:00, 22.21it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 448 images in the queue...\n",
            "===========================> Rendering remaining 422 images in the queue...\n",
            "===========================> Rendering remaining 341 images in the queue...\n",
            "===========================> Rendering remaining 260 images in the queue...\n",
            "===========================> Rendering remaining 178 images in the queue...\n",
            "===========================> Rendering remaining 98 images in the queue...\n",
            "===========================> Rendering remaining 20 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 896/896 [00:39<00:00, 22.47it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 469 images in the queue...\n",
            "===========================> Rendering remaining 443 images in the queue...\n",
            "===========================> Rendering remaining 417 images in the queue...\n",
            "===========================> Rendering remaining 392 images in the queue...\n",
            "===========================> Rendering remaining 327 images in the queue...\n",
            "===========================> Rendering remaining 246 images in the queue...\n",
            "===========================> Rendering remaining 166 images in the queue...\n",
            "===========================> Rendering remaining 88 images in the queue...\n",
            "===========================> Rendering remaining 10 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 896/896 [00:38<00:00, 23.41it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 498 images in the queue...\n",
            "===========================> Rendering remaining 472 images in the queue...\n",
            "===========================> Rendering remaining 447 images in the queue...\n",
            "===========================> Rendering remaining 421 images in the queue...\n",
            "===========================> Rendering remaining 380 images in the queue...\n",
            "===========================> Rendering remaining 298 images in the queue...\n",
            "===========================> Rendering remaining 217 images in the queue...\n",
            "===========================> Rendering remaining 137 images in the queue...\n",
            "===========================> Rendering remaining 61 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 1065/1065 [00:58<00:00, 18.25it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 485 images in the queue...\n",
            "===========================> Rendering remaining 458 images in the queue...\n",
            "===========================> Rendering remaining 431 images in the queue...\n",
            "===========================> Rendering remaining 405 images in the queue...\n",
            "===========================> Rendering remaining 378 images in the queue...\n",
            "===========================> Rendering remaining 352 images in the queue...\n",
            "===========================> Rendering remaining 326 images in the queue...\n",
            "===========================> Rendering remaining 299 images in the queue...\n",
            "===========================> Rendering remaining 273 images in the queue...\n",
            "===========================> Rendering remaining 226 images in the queue...\n",
            "===========================> Rendering remaining 144 images in the queue...\n",
            "===========================> Rendering remaining 64 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 1130/1130 [01:02<00:00, 18.21it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 541 images in the queue...\n",
            "===========================> Rendering remaining 515 images in the queue...\n",
            "===========================> Rendering remaining 490 images in the queue...\n",
            "===========================> Rendering remaining 463 images in the queue...\n",
            "===========================> Rendering remaining 437 images in the queue...\n",
            "===========================> Rendering remaining 411 images in the queue...\n",
            "===========================> Rendering remaining 385 images in the queue...\n",
            "===========================> Rendering remaining 360 images in the queue...\n",
            "===========================> Rendering remaining 283 images in the queue...\n",
            "===========================> Rendering remaining 202 images in the queue...\n",
            "===========================> Rendering remaining 121 images in the queue...\n",
            "===========================> Rendering remaining 41 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 830/830 [00:42<00:00, 19.74it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 396 images in the queue...\n",
            "===========================> Rendering remaining 370 images in the queue...\n",
            "===========================> Rendering remaining 344 images in the queue...\n",
            "===========================> Rendering remaining 284 images in the queue...\n",
            "===========================> Rendering remaining 201 images in the queue...\n",
            "===========================> Rendering remaining 119 images in the queue...\n",
            "===========================> Rendering remaining 37 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 362/362 [00:14<00:00, 25.68it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 137 images in the queue...\n",
            "===========================> Rendering remaining 111 images in the queue...\n",
            "===========================> Rendering remaining 43 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 427/427 [00:15<00:00, 27.40it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 188 images in the queue...\n",
            "===========================> Rendering remaining 163 images in the queue...\n",
            "===========================> Rendering remaining 138 images in the queue...\n",
            "===========================> Rendering remaining 112 images in the queue...\n",
            "===========================> Rendering remaining 50 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 380/380 [00:11<00:00, 32.31it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 168 images in the queue...\n",
            "===========================> Rendering remaining 142 images in the queue...\n",
            "===========================> Rendering remaining 116 images in the queue...\n",
            "===========================> Rendering remaining 63 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 353/353 [00:10<00:00, 34.59it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 183 images in the queue...\n",
            "===========================> Rendering remaining 166 images in the queue...\n",
            "===========================> Rendering remaining 148 images in the queue...\n",
            "===========================> Rendering remaining 131 images in the queue...\n",
            "===========================> Rendering remaining 115 images in the queue...\n",
            "===========================> Rendering remaining 78 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 487/487 [00:24<00:00, 19.85it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 174 images in the queue...\n",
            "===========================> Rendering remaining 148 images in the queue...\n",
            "===========================> Rendering remaining 122 images in the queue...\n",
            "===========================> Rendering remaining 83 images in the queue...\n",
            "===========================> Rendering remaining 3 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 648/648 [00:34<00:00, 18.66it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 331 images in the queue...\n",
            "===========================> Rendering remaining 313 images in the queue...\n",
            "===========================> Rendering remaining 293 images in the queue...\n",
            "===========================> Rendering remaining 267 images in the queue...\n",
            "===========================> Rendering remaining 241 images in the queue...\n",
            "===========================> Rendering remaining 215 images in the queue...\n",
            "===========================> Rendering remaining 189 images in the queue...\n",
            "===========================> Rendering remaining 164 images in the queue...\n",
            "===========================> Rendering remaining 139 images in the queue...\n",
            "===========================> Rendering remaining 112 images in the queue...\n",
            "===========================> Rendering remaining 50 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 486/486 [00:20<00:00, 24.25it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 201 images in the queue...\n",
            "===========================> Rendering remaining 175 images in the queue...\n",
            "===========================> Rendering remaining 150 images in the queue...\n",
            "===========================> Rendering remaining 124 images in the queue...\n",
            "===========================> Rendering remaining 88 images in the queue...\n",
            "===========================> Rendering remaining 6 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 505/505 [00:21<00:00, 23.37it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 210 images in the queue...\n",
            "===========================> Rendering remaining 185 images in the queue...\n",
            "===========================> Rendering remaining 161 images in the queue...\n",
            "===========================> Rendering remaining 135 images in the queue...\n",
            "===========================> Rendering remaining 110 images in the queue...\n",
            "===========================> Rendering remaining 46 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 555/555 [00:25<00:00, 21.37it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 259 images in the queue...\n",
            "===========================> Rendering remaining 234 images in the queue...\n",
            "===========================> Rendering remaining 209 images in the queue...\n",
            "===========================> Rendering remaining 184 images in the queue...\n",
            "===========================> Rendering remaining 160 images in the queue...\n",
            "===========================> Rendering remaining 135 images in the queue...\n",
            "===========================> Rendering remaining 110 images in the queue...\n",
            "===========================> Rendering remaining 49 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 555/555 [00:32<00:00, 16.89it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 223 images in the queue...\n",
            "===========================> Rendering remaining 198 images in the queue...\n",
            "===========================> Rendering remaining 173 images in the queue...\n",
            "===========================> Rendering remaining 149 images in the queue...\n",
            "===========================> Rendering remaining 123 images in the queue...\n",
            "===========================> Rendering remaining 91 images in the queue...\n",
            "===========================> Rendering remaining 12 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 462/462 [00:18<00:00, 24.39it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 181 images in the queue...\n",
            "===========================> Rendering remaining 156 images in the queue...\n",
            "===========================> Rendering remaining 131 images in the queue...\n",
            "===========================> Rendering remaining 106 images in the queue...\n",
            "===========================> Rendering remaining 81 images in the queue...\n",
            "===========================> Rendering remaining 6 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 401/401 [00:14<00:00, 27.81it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 161 images in the queue...\n",
            "===========================> Rendering remaining 136 images in the queue...\n",
            "===========================> Rendering remaining 110 images in the queue...\n",
            "===========================> Rendering remaining 84 images in the queue...\n",
            "===========================> Rendering remaining 15 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 419/419 [00:16<00:00, 25.58it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 168 images in the queue...\n",
            "===========================> Rendering remaining 143 images in the queue...\n",
            "===========================> Rendering remaining 117 images in the queue...\n",
            "===========================> Rendering remaining 92 images in the queue...\n",
            "===========================> Rendering remaining 67 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 255/255 [00:07<00:00, 35.42it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 100 images in the queue...\n",
            "===========================> Rendering remaining 66 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 353/353 [00:11<00:00, 31.14it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 144 images in the queue...\n",
            "===========================> Rendering remaining 119 images in the queue...\n",
            "===========================> Rendering remaining 94 images in the queue...\n",
            "===========================> Rendering remaining 44 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 430/430 [00:16<00:00, 26.16it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 174 images in the queue...\n",
            "===========================> Rendering remaining 148 images in the queue...\n",
            "===========================> Rendering remaining 123 images in the queue...\n",
            "===========================> Rendering remaining 98 images in the queue...\n",
            "===========================> Rendering remaining 58 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 466/466 [00:19<00:00, 23.73it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 186 images in the queue...\n",
            "===========================> Rendering remaining 162 images in the queue...\n",
            "===========================> Rendering remaining 137 images in the queue...\n",
            "===========================> Rendering remaining 112 images in the queue...\n",
            "===========================> Rendering remaining 86 images in the queue...\n",
            "===========================> Rendering remaining 20 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 304/304 [00:08<00:00, 37.17it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 129 images in the queue...\n",
            "===========================> Rendering remaining 105 images in the queue...\n",
            "===========================> Rendering remaining 80 images in the queue...\n",
            "===========================> Rendering remaining 6 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 432/432 [00:20<00:00, 20.87it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 145 images in the queue...\n",
            "===========================> Rendering remaining 121 images in the queue...\n",
            "===========================> Rendering remaining 95 images in the queue...\n",
            "===========================> Rendering remaining 50 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 411/411 [00:14<00:00, 27.96it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 171 images in the queue...\n",
            "===========================> Rendering remaining 146 images in the queue...\n",
            "===========================> Rendering remaining 121 images in the queue...\n",
            "===========================> Rendering remaining 96 images in the queue...\n",
            "===========================> Rendering remaining 55 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 480/480 [00:24<00:00, 19.35it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 161 images in the queue...\n",
            "===========================> Rendering remaining 137 images in the queue...\n",
            "===========================> Rendering remaining 111 images in the queue...\n",
            "===========================> Rendering remaining 87 images in the queue...\n",
            "===========================> Rendering remaining 62 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 405/405 [00:14<00:00, 27.96it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 166 images in the queue...\n",
            "===========================> Rendering remaining 141 images in the queue...\n",
            "===========================> Rendering remaining 115 images in the queue...\n",
            "===========================> Rendering remaining 89 images in the queue...\n",
            "===========================> Rendering remaining 37 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 501/501 [00:23<00:00, 21.61it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 196 images in the queue...\n",
            "===========================> Rendering remaining 171 images in the queue...\n",
            "===========================> Rendering remaining 144 images in the queue...\n",
            "===========================> Rendering remaining 117 images in the queue...\n",
            "===========================> Rendering remaining 91 images in the queue...\n",
            "===========================> Rendering remaining 37 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 414/414 [00:14<00:00, 29.09it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 158 images in the queue...\n",
            "===========================> Rendering remaining 130 images in the queue...\n",
            "===========================> Rendering remaining 100 images in the queue...\n",
            "===========================> Rendering remaining 62 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 462/462 [00:18<00:00, 24.82it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 172 images in the queue...\n",
            "===========================> Rendering remaining 149 images in the queue...\n",
            "===========================> Rendering remaining 124 images in the queue...\n",
            "===========================> Rendering remaining 102 images in the queue...\n",
            "===========================> Rendering remaining 74 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            "100% 794/794 [00:37<00:00, 21.34it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 376 images in the queue...\n",
            "===========================> Rendering remaining 350 images in the queue...\n",
            "===========================> Rendering remaining 324 images in the queue...\n",
            "===========================> Rendering remaining 298 images in the queue...\n",
            "===========================> Rendering remaining 270 images in the queue...\n",
            "===========================> Rendering remaining 196 images in the queue...\n",
            "===========================> Rendering remaining 120 images in the queue...\n",
            "===========================> Rendering remaining 41 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n",
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "Try to use other video encoders...\n",
            " 56% 559/1002 [00:48<00:17, 25.60it/s]"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}